{"meta":{"title":"Mon's Blogs","subtitle":"技术分享、共同进步","description":"Mon's blogs","author":"Mon","url":"http://example.com","root":"/"},"pages":[{"title":"about","date":"2023-08-21T03:30:54.000Z","updated":"2023-08-21T03:31:30.980Z","comments":true,"path":"about/index.html","permalink":"http://example.com/about/index.html","excerpt":"","text":"this is page for about me"},{"title":"categories","date":"2023-08-21T03:25:59.000Z","updated":"2023-08-21T03:28:56.900Z","comments":true,"path":"categories/index.html","permalink":"http://example.com/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2023-08-21T03:29:33.000Z","updated":"2023-08-21T03:31:17.416Z","comments":true,"path":"tags/index.html","permalink":"http://example.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"redis-data-structure","slug":"redis-data-structure","date":"2024-01-16T09:47:37.000Z","updated":"2024-01-23T08:22:06.516Z","comments":false,"path":"2024/01/16/redis-data-structure/","link":"","permalink":"http://example.com/2024/01/16/redis-data-structure/","excerpt":"","text":"Redis中的数据结构Redis之所以这么快，除了因为它是基于内存的数据库之外，另一个重要的因素就是它底层的数据结构使得我们对数据的操作能得到高效地处理。 接下来，我们就来了解一下Redis中一些高效、优雅的数据结构吧。 Redis中的数据类型与数据结构对应关系需要注意的是，我们这里讨论的数据结构，并不是指“String”、“List”、“Hash”、“Set”、“Zset”这些Redis中的基本数据类型，而是“SDS”、“QuickList”、“Dict”、“ZipList”、“SkipList”、“ListPack”、“IntSet”等这些更加底层的被基本数据类型所使用的数据结构，下面放一张数据类型与数据结构对应关系图供参考： 由上图可以知道，“ZipList”这个数据结构并未出现，这是因为随着Redis版本的迭代，它已经被性能更好的“ListPack”取代了。当然，这并不意味着“ZipList”就已经退出了历史舞台，至少“QuickList”还是基于它的。 Redis底层数据结构接下来，就来聊一聊Redis底层的数据结构吧。 SDS“SDS”的全称为“Simple Dynamic String”，它是一个带了额外信息的字节数组： 123456struct SDS&lt;T&gt; &#123; T capacity; // 数组容量 T len; // 数组长度 byte flags; // 特殊标志位 byte[] content; // 数组内容&#125; Dict字典是Redis中使用频率最高的数据结构，不仅hash这个数据类型使用了字典，整个Redis数据库的所有key和value也组成一个全局字典，带过期时间的key集合也是一个字典，zset集合中存储value和score的映射关系也是一个字典。 字典结构字典内部包含了两个hashtable，一般情况下只会有一个hashtable有值，但是在字典进行扩容缩容时，会重新分配一个新的hashtable来进行渐进式rehash，这个时候两个hashtable中都会存在值，直到rehash完成，所有的值都搬迁到了新的hashtable之后，旧的hashtable才会被删除，此时又回到只有一个hashtable的状态了。 通过上述描述可知，hashtable才是Dict结构的核心，hashtable是一个二维的数组链表，第一维是一个数组，存储着指向链表头节点的指针，第二维便是一个链表。 渐进式rehash当字典需要进行扩容缩容时，需要重新申请一个数组来存放字典中的值，当字典内的值非常多时，这样一个大字典的扩缩容会消耗一个O(n)的时间，这对使用单线程的Redis来说是很难承受的，所以Redis使用渐进式rehash进行小步搬迁。 搬迁操作可以由来自客户端的hset、hdel等指令来间接触发，也可以由Redis的定时任务来触发一个主动搬迁。 查找hashtable中的元素都存储在链表中，要找到一个元素，首先需要定位到这个元素在哪个链表上，Redis中通过对元素进行一个hash计算，将key映射成一个整数，而这个整数就是这个元素所处的链表在数组中的位置下标。找到链表之后，通过遍历这个链表来查找到这个元素。 扩&#x2F;缩容条件 扩容 当hash表中的元素个数等于第一维数组的长度时，就会开始扩容，扩容的数组是原来数组长度的两倍。不过如果Redis正在执行bgsave指令的话，Redis只会在元素个数达到了第一维数组长度的5倍的时候进行扩容。 缩容 当hashtable中的元素被逐渐删除而越来越稀疏时，Redis会对hashtable进行缩容来节省内存。缩容的条件是元素个数低于数组长度的10%，缩容不会考虑Redis是否正在执行bgsave。 ZipListRedis为了节省内存空间而设计了压缩列表这个数据结构。压缩列表是一块连续的内存空间，元素之间紧紧相邻，没有冗余空间。 随着Redis的迭代升级，现在的Redis对象不会再直接使用压缩列表这个结构，而是使用基于压缩列表实现的快速列表来存储元素。 zlbytes：整个压缩列表占用的字节数； zltail_offset：最后一个元素距离压缩列表起始位置的偏移量，用于快速定位到最后一个节点； zllength：元素个数； zlend：压缩列表结束标志，恒为0xFF. 压缩列表中每个元素中包含如下字段： prelen：前一个entry的字节长度； encoding：元素编码类型； content：元素内容。 prelen字段表示前一个元素的字节长度，当压缩列表倒序遍历时，需要通过这个字段来快速定位到上一个元素的位置。它是一个变长的整数，当字符串长度小于254时，使用一个字节表示，如果达到或超出254时，就会使用5个字节来表示。 encoding字段存储了内容元素的编码类型信息，压缩列表通过这个字段来决定后面的content的形式。 Redis为了节约存储空间，对encoding这个字段进行了相当复杂的设计，Redis通过这个字段的前缀位来识别具体存储的数据形式： 00xxxxxx：最大长度位数为63的短字符串，后面的6个位存储字符串的位数，剩余的字节就是字符串的内容； 01xxxxxx xxxxxxxx：中等长度的字符串，后面14个位来表示字符串的长度，剩余的字节就是字符串的内容； 10000000 aaaaaaaa bbbbbbbb cccccccc dddddddd：特大字符串，需要使用额外4个字节来表示长度。第一个字节前缀是10，剩余6位没有使用，统一为0。这种大字符串通常是没有机会使用到的，因为压缩列表一般只用来存储小数据。 11000000：int16； 11010000：int32； 11100000：int64； 11110000：int24； 11111110：int8； 11111111：ziplist的结束，也就是zlend的值0xFF。 1111xxxx：极小整数，xxxx的范围只能是0001～1101，也就是1～13，因为0000、1110、1111都被占用了。读取到的value需要将xxxx减1，也就是它的最终值的范围是0～12。 需要注意的是，content字段在结构中是被定义为optional，表示这个字段是可选的，对于很小的整数来说，它的内容已经被包含到encoding字段的尾部了。 添加元素因为压缩列表是紧凑存储的，没有冗余的空间，这也就意味着在添加元素时需要拓展压缩列表的内存，取决于内存分配算法和压缩列表的当前状态，拓展压缩列表内存时，可能会开辟一份新的内存空间，然后将压缩列表中的元素复制到新的内存中，也可能在原有的地址上进行拓展，这样就不需要对旧的元素进行拷贝。 正是因为拓展内存可能进行旧元素的拷贝，当压缩列表过大时，会带来很大的性能消耗，所以压缩列表不适合用来存储大型的元素。 级联更新上文提到了每个元素都会有一个prevlen字段存储前一个元素的长度。如果内容小于254字节，prevlen字段使用一个字节存储，否则就使用5个字节存储。这意味着如果某个元素长度从253字节变成了254个字节，那么它的下一个元素的prevlen字段就要更新，如果刚好后面这个元素的长度本来也是253个字节，那么这个元素后面的元素也要跟着修改…… 由此触发了一个级联更新，带来了额外的性能消耗。 QuickListRedis早期list数据类型使用ZipList和LinkerList来存储元素，当元素较少时使用ZipList，元素较多时使用LinkedList。但是考虑到LinkedList每个节点都需要存储前后指针来将节点串联起来，这就带来了额外的内存消耗，且每个节点的内存都是单独分配，容易导致出现内存碎片。而ZipList则由于存在“级联更新”的风险，所以基于这两个结构的弊端，Redis设计了QuickList这个数据结构，这个数据结构是基于LinkedList和ZipList的，整合了两个结构的优势，下面是QuickList的结构： QuickList是ZipList和LinkedList的结合体，上图中的每个quicklist-node组成一个LinkedList，并包含一个指向ZipList的引用，一个QuickList持有两个分别指向头节点和尾节点的引用来定位元素节点。 每个QuickList的节点持有的ZipList都比较小，这样就能极大的减小ZipList级联更新带来的影响。 SkipList介绍SkipList之前，我们先来聊一聊LinkedList这个数据结构，在LinkedList这个结构中，各个节点之间使用前后指针相互串联，能在O（1）的时间内完成节点的插入、删除等操作，但是其弊端便是检索元素，无论LinkedList有序还是无序，都需要O（n）的时间来检索目标元素，这样的效率对于单线程的Redis来说，是不可接受的。 那么有没有办法提高这样的检索效率呢？接下来就轮到本小节的主角登场了： 可以把SkipList想象成是一个LinkedList，只不过与LinkedList不同的是，部分元素节点会“长高”，所有的节点都具备基本的高度1，部分节点会长高到2，高度为2的节点中又有部分节点会长高到3，依此类推，SkipList支持的最大高度是64。 当我们需要在SkipList中检索某个元素时，都会从最高的一层开始查找，找到这一层中最后一个比目标值小的元素之后，从这个元素开始下降到下一层继续找到下一层中的最后一个比目标元素小的节点，依此查找下去，直到找到目标元素为止。 可以比对一下SkipList和LinkedList的查找方式，可以发现SkipList是通过高层级的元素进行跳跃式查找的，而不是像LinkedList那样只能一个挨着一个元素查找，这样的查询效率可以从LinkedList的O(n)下降到O(lg(n))。 ListPack从Redis5.0开始引入了一个新的数据结构ListPack，这是ZipList的改进版，比ZipList更加节省内存空间，结构上也更加精简，ListPack结构与ZipList相似，只是少了zltail_offset字段，且其内部的元素节点的结构也稍有不同，元素节点不再存储上一个元素的长度，而是当前元素的长度，也正是这一改变，ListPack中不再存在ZipList中的级联更新。 本文只是简单介绍了一下Redis中的各个数据结构，针对每个数据结构的详细介绍，将会在后续的文章中进行。","categories":[{"name":"Redis","slug":"Redis","permalink":"http://example.com/categories/Redis/"},{"name":"Basic","slug":"Redis/Basic","permalink":"http://example.com/categories/Redis/Basic/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://example.com/tags/Redis/"},{"name":"DataStructure","slug":"DataStructure","permalink":"http://example.com/tags/DataStructure/"}]},{"title":"es-search-types","slug":"es-search-types","date":"2024-01-08T05:55:59.000Z","updated":"2024-01-18T10:02:40.741Z","comments":false,"path":"2024/01/08/es-search-types/","link":"","permalink":"http://example.com/2024/01/08/es-search-types/","excerpt":"","text":"ES查询类型总结","categories":[{"name":"中间件","slug":"中间件","permalink":"http://example.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"搜索","slug":"中间件/搜索","permalink":"http://example.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2/"},{"name":"ES","slug":"中间件/搜索/ES","permalink":"http://example.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2/ES/"}],"tags":[{"name":"ES","slug":"ES","permalink":"http://example.com/tags/ES/"}]},{"title":"test-code-library","slug":"test-code-library","date":"2024-01-03T08:56:11.000Z","updated":"2024-01-18T10:00:39.071Z","comments":false,"path":"2024/01/03/test-code-library/","link":"","permalink":"http://example.com/2024/01/03/test-code-library/","excerpt":"","text":"","categories":[{"name":"代码库","slug":"代码库","permalink":"http://example.com/categories/%E4%BB%A3%E7%A0%81%E5%BA%93/"},{"name":"Java","slug":"代码库/Java","permalink":"http://example.com/categories/%E4%BB%A3%E7%A0%81%E5%BA%93/Java/"},{"name":"回复邮件","slug":"代码库/Java/回复邮件","permalink":"http://example.com/categories/%E4%BB%A3%E7%A0%81%E5%BA%93/Java/%E5%9B%9E%E5%A4%8D%E9%82%AE%E4%BB%B6/"}],"tags":[{"name":"代码库","slug":"代码库","permalink":"http://example.com/tags/%E4%BB%A3%E7%A0%81%E5%BA%93/"}]},{"title":"message_queue_comparation","slug":"message-queue-comparation","date":"2023-12-20T03:11:22.000Z","updated":"2024-01-18T09:59:33.798Z","comments":false,"path":"2023/12/20/message-queue-comparation/","link":"","permalink":"http://example.com/2023/12/20/message-queue-comparation/","excerpt":"","text":"主流消息队列Rabbit MQ消息模型xxx 优缺点xxx Rocket MQ消息模型xxx 优缺点xxx Kafka消息模型xxx 优缺点xxx Pulsar消息模型xxx 优缺点xxx 横向比对","categories":[{"name":"消息队列","slug":"消息队列","permalink":"http://example.com/categories/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"消息队列比对","slug":"消息队列/消息队列比对","permalink":"http://example.com/categories/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E6%AF%94%E5%AF%B9/"}],"tags":[{"name":"消息队列","slug":"消息队列","permalink":"http://example.com/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"}]},{"title":"springboot-websocket","slug":"springboot-websocket","date":"2023-12-02T16:31:37.000Z","updated":"2024-01-18T10:00:23.824Z","comments":false,"path":"2023/12/03/springboot-websocket/","link":"","permalink":"http://example.com/2023/12/03/springboot-websocket/","excerpt":"","text":"SpringBoot中使用Websocket进行全双工通信本文基于SpringBoot的Web服务来使用Websocket进行全双工通信，即项目的基础是一个已经可以提供http请求的Web服务。 引入依赖12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-websocket&lt;/artifactId&gt; &lt;version&gt;2.7.0&lt;/version&gt;&lt;/dependency&gt; 配置配置消息处理器消息处理器负责处理来自客户端的活动，例如客户端连接、断开连接、发来消息等。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354package xxx;import lombok.extern.slf4j.Slf4j;import org.springframework.web.socket.CloseStatus;import org.springframework.web.socket.TextMessage;import org.springframework.web.socket.WebSocketSession;import org.springframework.web.socket.handler.TextWebSocketHandler;import java.io.IOException;import java.util.Map;import java.util.concurrent.ConcurrentHashMap;@Slf4jpublic class MyHandler extends TextWebSocketHandler &#123; private static final String INSTANCE_ID_KEY = &quot;instanceId&quot;; // 存储WebSocket会话，key为客户端id private final Map&lt;String, WebSocketSession&gt; sessionMap; public MyHandler() &#123; this.sessionMap = new ConcurrentHashMap&lt;&gt;(); &#125; @Override protected void handleTextMessage(WebSocketSession session, TextMessage message) throws Exception &#123; // 处理客户端发来的消息 String messageString = message.getPayload(); String instanceId = getAttributeAsString(session, INSTANCE_ID_KEY); log.info(&quot;received message: &#123;&#125; from instance &#123;&#125;&quot;, messageString, instanceId); &#125; @Override public void afterConnectionEstablished(WebSocketSession session) throws Exception &#123; // 处理连接成功，将会话存入Map String instanceId = getAttributeAsString(session, INSTANCE_ID_KEY); log.info(&quot;instanceId &#123;&#125; connected&quot;, instanceId); sessionMap.put(instanceId, session); &#125; @Override public void afterConnectionClosed(WebSocketSession session, CloseStatus status) throws Exception &#123; // 处理客户端断开连接，将会话从Map中移除 String instanceId = getAttributeAsString(session, INSTANCE_ID_KEY); sessionMap.remove(instanceId); session.close(); String reason = status.getReason(); log.info(&quot;instance &#123;&#125; closed with reason: &#123;&#125;&quot;, instanceId, reason); &#125; private String getAttributeAsString(WebSocketSession session, String attributeName) &#123; Map&lt;String, Object&gt; attributes = session.getAttributes(); return attributes.get(attributeName).toString(); &#125;&#125; 配置握手拦截器握手拦截器可以在Websocket协议进行连接握手时自定义握手逻辑，通常可以用来实现连接认证等功能。 1234567891011121314151617181920212223242526272829303132333435363738394041package xxx;import lombok.extern.slf4j.Slf4j;import org.springframework.beans.factory.annotation.Value;import org.springframework.http.server.ServerHttpRequest;import org.springframework.http.server.ServerHttpResponse;import org.springframework.stereotype.Component;import org.springframework.web.socket.WebSocketHandler;import org.springframework.web.socket.server.support.HttpSessionHandshakeInterceptor;import java.util.List;import java.util.Map;@Slf4j@Componentpublic class MyInterceptor extends HttpSessionHandshakeInterceptor &#123; @Value(&quot;$&#123;wbs.enrollToken&#125;&quot;) private String enrollToken; @Override public boolean beforeHandshake(ServerHttpRequest request, ServerHttpResponse response, WebSocketHandler wsHandler, Map&lt;String, Object&gt; attributes) throws Exception &#123; // 从请求头中获取认证数据进行认证 Map&lt;String, List&lt;String&gt;&gt; headers = request.getHeaders(); List&lt;String&gt; authorization = headers.get(&quot;Authorization&quot;); if (authorization == null) &#123; log.info(&quot;not found header: Authorization&quot;); return false; &#125; List&lt;String&gt; instanceId = headers.get(&quot;instanceId&quot;); if (instanceId == null || instanceId.isEmpty()) &#123; log.info(&quot;Reject connection because of instance id is required&quot;); return false; &#125; String token = authorization.get(0); if (!enrollToken.equals(token)) &#123; log.info(&quot;Reject connection from instance &#123;&#125; because of incorrect Authorization token&quot;, instanceId); return false; &#125; // 将客户端id存入会话的参数集合中 attributes.put(&quot;instanceId&quot;, instanceId.get(0)); return true; &#125;&#125; 配置Websocket服务端点1234567891011121314151617181920212223242526package xxx;import xxx.xxx.MyHandler;import xxx.xxx.MyInterceptor;import org.springframework.context.annotation.Configuration;import org.springframework.web.socket.config.annotation.EnableWebSocket;import org.springframework.web.socket.config.annotation.WebSocketConfigurer;import org.springframework.web.socket.config.annotation.WebSocketHandlerRegistry;import javax.annotation.Resource;@Configuration@EnableWebSocketpublic class MyConfig implements WebSocketConfigurer &#123; @Resource private MyInterceptor myInterceptor; @Override public void registerWebSocketHandlers(WebSocketHandlerRegistry registry) &#123; // 添加/wbs端点 registry.addHandler(new MyHandler(), &quot;/wbs&quot;) // 跨域配置 .setAllowedOrigins(&quot;*&quot;) .addInterceptors(myInterceptor); &#125;&#125; 进行如上配置，将在&#x2F;wbs路径上启动一个Websocket服务端点，请求协议为：ws:&#x2F;&#x2F;ip:port&#x2F;wbs","categories":[{"name":"通信协议","slug":"通信协议","permalink":"http://example.com/categories/%E9%80%9A%E4%BF%A1%E5%8D%8F%E8%AE%AE/"},{"name":"Websocket","slug":"通信协议/Websocket","permalink":"http://example.com/categories/%E9%80%9A%E4%BF%A1%E5%8D%8F%E8%AE%AE/Websocket/"}],"tags":[{"name":"Websocket","slug":"Websocket","permalink":"http://example.com/tags/Websocket/"},{"name":"全双工通信","slug":"全双工通信","permalink":"http://example.com/tags/%E5%85%A8%E5%8F%8C%E5%B7%A5%E9%80%9A%E4%BF%A1/"}]},{"title":"raft_leader_election","slug":"raft-leader-election","date":"2023-11-01T06:36:24.000Z","updated":"2024-01-18T10:03:04.848Z","comments":false,"path":"2023/11/01/raft-leader-election/","link":"","permalink":"http://example.com/2023/11/01/raft-leader-election/","excerpt":"","text":"一、基本概念角色在Raft算法中，服务器在任何时刻都只能处于以下三种角色之一： 领导者（Leader）：领导者负责处理所有客户端请求并负责日志复制，同一时刻最多只能有一个正常工作的领导者； 跟随者（Follower）：跟随者完全被动地处理请求，跟随者不主动发送RPC请求，只响应收到的RPC请求，服务器大多数时间都处于这种角色； 候选者（Candidate）：候选者是一种处于领导者和跟随者之间的中间状态，这个状态是暂时的，候选者如果得到大多数节点的投票，将成为领导者，否则状态退回跟随者。 任期任期就是一个逻辑时间段，Raft算法将分布式系统中的时间划分为一个个不同的任期来解决时序问题。每个任期都有一个数字的任期号，任期号在初始启动时为0，单调递增切永不重复。 一个正常的任期至少有一个领导者，任期通常被分为两部分：一个是任期开始时的选举过程，另一个是任期正常运行的部分。 有些任期内没有选举出领导，这时会立即进入下一个任期，再次尝试选出一个领导者（如Term 1）。 每台服务器需要维护一个currentTerm变量，表示服务器当前已知的最新任期号，变量currentTerm必须持久化存储，以便在服务器宕机重启时能够知道最新任期。 任期对Raft算法十分重要，它能够帮助Raft识别过期的信息，Raft只使用最新任期的信息。 RPC通信Raft算法中服务器之间的通信主要通过两个RPC调用实现，一个是用于选举领导者的RequestVote RPC，另一个是AppendEntries RPC，用于复制日志和发送心跳。 二、领导选举选举流程Raft算法启动的第一步就是要选举出领导者。每个节点在启动时都是跟随者状态，跟随者只能被动地接收来自领导者或者候选者的RPC请求。 领导者想要保持自己的领导地位，就必须周期性地向集群中的其它节点发送心跳包（即空的appendEntities消息）。 如果一个跟随者在一个选举超时时间内没有收到任何任期更大的RPC请求，则该节点认为集群中没有领导者，于是它将开启新的一轮选举，该节点的状态流转如图： 对状态流程图说明： 某跟随者节点失去领导者的心跳，角色转换为候选者； 增加自己的当前任期，进入下一任期； 先给自己投一票； 并行地向系统中的其它节点发送requestVote消息索要选票，并不断进行重试直到收到各节点的响应； 得到各节点响应后根据响应情况出现如下几种情况： 获得超过半数的选票，该节点成为领导者； 收到来自领导者的appendEntities消息，说明此时系统中已经存在领导者了，于是它转变成跟随者； 经过一个选举超时时间之后都未发生如上情况，于是节点将自己任期+1重新开始新的一轮投票。 选举特性保证选举过程中需要保证共识算法的两个特性：安全性和活性。 安全性是指一个任期内只会有一个领导者被选举出来；活性是指要确保系统最终能选出一个领导者。 要保证安全性，需要做到： 每个节点在同一任期只能投一次票，它将投给满足第一个条件的RequestVote请求，然后拒绝其他候选者的请求。这需要每个节点新增一个投票信息变量voteFor，表示当前任期内选票投给了哪个候选者，如果没有投票，则voteFor为空。投票信息voteFor也要持久化存储，以便节点宕机重启后恢复投票信息，否则节点重启后voteFor信息丢失，会导致一个节点投票给不同的候选者。 只有获得超过半数节点的选票才能成为领导者，也就是说，两个不同的候选者无法在同一任期内都获得超过半数节点的选票。 要保证活性，需要做到： 在一个任期内无法选举出领导者时，需要重新发起投票，直到系统中出现领导者 但是这样会出现问题：多个跟随者一直同时成为候选者并发起投票的话，这个分割选票的过程将会无限进行下去，出现活锁问题。 为了解决活锁问题，我们可以选择节点随机选择超时时间的办法，让节点选择一个随机的选举超时时间，这样的话，即使上一轮多个节点同时开启选举，也会因为选举超时时间不一致而在不同的时间开启下一轮选举。采用这种办法之后，先开启下一轮的节点将被优先选为领导者。 领导选举限制上文中介绍了Raft算法的领导选举流程，那么有个问题：怎样的候选者，才能获得跟随者的选票呢？ Raft算法通过如下操作来限制候选者成为领导者： 候选者C在RequestVote消息中包含自己日志中的最后一条日志条目的索引（lastIndex）和任期（lastTerm）。 收到投票请求的服务器V将和候选者C比较谁的日志更完整，如果服务器V的任期比候选者C新，或者任期一样，但是服务器V最后一条日志的索引比候选者C的大，那么V将拒绝投票给C。（任期比较的优先级更高） 通过这个限制，就能保证选出来的领导者比集群中超过半数的节点拥有更完整的日志。 极端情况下领导选举的活性问题 预投票 领导主动下台 三、日志复制日志格式与提交逻辑我们先来了解一下Raft算法中的日志格式。每个节点存储自己的日志副本，日志中的每个日志条目包含如下内容： 索引（Index）：索引表示该日志条目在整个日志中的位置； 任期号：日志条目首次被领导者创建时的任期； 命令：应用于状态机的命令。 Raft算法通过索引和任期号唯一索引一条日志记录，而命令是我们所不关心的。 日志必须持久化存储，一个节点必须先将日志条目安全地写到磁盘中，才能向系统中的其它节点发送请求或回复请求。 如果一条日志条目别存储在超过半数以上的节点上，则可以认为该记录已提交，这是Raft算法非常重要的一个特性。如果一条记录已经被提交，这就意味着状态机可以安全地执行该记录，这条记录就不能再改变了。 如上图，第一条到第七条日志已经提交，可以安全应用到状态机了，而第八条记录尚未提交，不能应用到状态机。 Raft算法通过AppendEntries消息来复制日志，和心跳共用一个RPC，不过AppendEntries消息用来发送心跳消息时不包含日志信息。 日志复制流程Raft算法正常运行时，日志复制流程为： 客户端向领导者发送命令； 领导者先将该命令追加到自己的日志中，确保日志持久化存储； 领导者并行地向其他节点发送AppendEntries消息，等待响应‘ 如果收到超过半数节点的响应，则认为新的日志记录已提交。接着领导者将命令应用到自己的状态机，然后想客户端返回响应。此外，一旦领导者提交了一个日志记录，将在后续的AppendEntries消息中通过LeaderCommit参数通知跟随者，该参数代表领导者已提交的最大的日志索引，跟随者也将提交日志索引不大于LeaderCommit的日志，并将日志中的命令应用到自己的状态机。 如果跟随者宕机或者响应超时，日志没有复制成功，那么领导者将反复尝试发送AppendEntries消息。 性能优化：领导者不必等到所有跟随者响应，只需要超过半数的跟随者成功响应就可以回复客户端了。这样保证了即使系统中有个响应很慢的节点也不会拖垮整个系统的性能。 日志一致性检查为了保证日志的一致性，Raft算法维持了以下两个特性： 如果两个节点的日志在相同位置上的任期相同，则认为它们具有一样的命令，并且从日志开头到这个索引位置之间的日志也完全相同； 如果给定的记录已经提交，那么前面的日志也已经提交，即Raft算法不允许出现日志空洞。 为了维护这两个特性，Raft算法采取了如下做法： Raft算法通过AppendEntries消息来检测之前的一个日志条目，每个AppendEntries消息请求包含新日志条目之前一个日志条目的索引（prevLogIndex）和任期（prevLogTerm）。跟随者收到请求后，会检查自己最后一条日志的索引以及任期是否与请求消息中的prevLogIndex和prevLogTerm相匹配，如果匹配则接收该记录，否则拒绝。 这个流程被称为“日志一致性检查”。 需要注意的是，跟随者需要具备处理重复RPC请求的能力。","categories":[{"name":"分布式共识算法","slug":"分布式共识算法","permalink":"http://example.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E5%85%B1%E8%AF%86%E7%AE%97%E6%B3%95/"},{"name":"Raft","slug":"分布式共识算法/Raft","permalink":"http://example.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E5%85%B1%E8%AF%86%E7%AE%97%E6%B3%95/Raft/"},{"name":"领导选举","slug":"分布式共识算法/Raft/领导选举","permalink":"http://example.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E5%85%B1%E8%AF%86%E7%AE%97%E6%B3%95/Raft/%E9%A2%86%E5%AF%BC%E9%80%89%E4%B8%BE/"}],"tags":[{"name":"分布式共识","slug":"分布式共识","permalink":"http://example.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E5%85%B1%E8%AF%86/"},{"name":"领导选举","slug":"领导选举","permalink":"http://example.com/tags/%E9%A2%86%E5%AF%BC%E9%80%89%E4%B8%BE/"}]},{"title":"mongodb-cluster-deploy","slug":"mongodb-cluster-deploy","date":"2023-10-13T08:03:22.000Z","updated":"2024-01-18T09:59:52.873Z","comments":false,"path":"2023/10/13/mongodb-cluster-deploy/","link":"","permalink":"http://example.com/2023/10/13/mongodb-cluster-deploy/","excerpt":"","text":"docker搭建mongodb集群一、准备工作1、拉取Mongodb镜像1docker pull mongo 2、安装docker-compose工具 使用apt安装 1apt install docker-compose 使用pip安装 1pip install docker-compose 3、创建相关文件夹1mkdir -p /home/mongo-cluster 二、开始构建1、集群规划 容器名称 端口号 目录 角色 mongo_router_100 27017:27017 - Router mongo_configsvc_101 27101:27019 &#x2F;home&#x2F;mongo-cluster&#x2F;config_servers&#x2F;101 Config Server 1 mongo_configsvc_102 27102:27019 &#x2F;home&#x2F;mongo-cluster&#x2F;config_servers&#x2F;102 Config Server 2 mongo_shard_a_111 27111:27018 &#x2F;home&#x2F;mongo-cluster&#x2F;A&#x2F;111 Shard A Master mongo_shard_a_112 27112:27018 &#x2F;home&#x2F;mongo-cluster&#x2F;A&#x2F;112 Shard A Secondary mongo_shard_a_113 27113:27018 &#x2F;home&#x2F;mongo-cluster&#x2F;A&#x2F;113 Shard A Arbiter mongo_shard_b_121 27121:27018 &#x2F;home&#x2F;mongo-cluster&#x2F;B&#x2F;121 Shard B Master mongo_shard_b_122 27122:27018 &#x2F;home&#x2F;mongo-cluster&#x2F;B&#x2F;122 Shard B Secondary mongo_shard_b_123 27123:27018 &#x2F;home&#x2F;mongo-cluster&#x2F;B&#x2F;123 Shard B Arbiter 2、准备keyfile12openssl rand -base64 756 &gt; /home/mongo-cluster/mongo-keyfilechmod 400 /home/mongo-cluster/mongo-keyfile 3、编写docker-compose.yml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124version: &#x27;3.6&#x27;services: shard_A_111: image: mongo container_name: mongo_shard_a_111 ports: - 27111:27018 command: /bin/bash -c &quot;chown 999:999 /data/mongo-keyfile &amp;&amp; mongod --keyFile /data/mongo-keyfile --shardsvr --directoryperdb --replSet shard_A --bind_ip 0.0.0.0&quot; volumes: - /home/mongo-cluster/A/111:/data/db - /home/mongo-cluster/mongo-keyfile:/data/mongo-keyfile privileged: true networks: - mongo secondary_A_112: image: mongo container_name: mongo_shard_a_112 ports: - 27112:27018 command: /bin/bash -c &quot;chown 999:999 /data/mongo-keyfile &amp;&amp; mongod --keyFile /data/mongo-keyfile --shardsvr --directoryperdb --replSet shard_A --bind_ip 0.0.0.0&quot; volumes: - /home/mongo-cluster/A/112:/data/db - /home/mongo-cluster/mongo-keyfile:/data/mongo-keyfile privileged: true networks: - mongo arbiter_A_113: image: mongo container_name: mongo_shard_a_113 ports: - 27113:27018 command: /bin/bash -c &quot;chown 999:999 /data/mongo-keyfile &amp;&amp; mongod --keyFile /data/mongo-keyfile --shardsvr --directoryperdb --replSet shard_A --bind_ip 0.0.0.0&quot; volumes: - /home/mongo-cluster/A/113:/data/db - /home/mongo-cluster/mongo-keyfile:/data/mongo-keyfile privileged: true networks: - mongo shard_B_121: image: mongo container_name: mongo_shard_b_121 ports: - 27121:27018 command: /bin/bash -c &quot;chown 999:999 /data/mongo-keyfile &amp;&amp; mongod --keyFile /data/mongo-keyfile --shardsvr --directoryperdb --replSet shard_B --bind_ip 0.0.0.0&quot; volumes: - /home/mongo-cluster/B/121:/data/db - /home/mongo-cluster/mongo-keyfile:/data/mongo-keyfile privileged: true networks: - mongo secondary_B_122: image: mongo container_name: mongo_shard_b_122 ports: - 27122:27018 command: /bin/bash -c &quot;chown 999:999 /data/mongo-keyfile &amp;&amp; mongod --keyFile /data/mongo-keyfile --shardsvr --directoryperdb --replSet shard_B --bind_ip 0.0.0.0&quot; volumes: - /home/mongo-cluster/B/122:/data/db - /home/mongo-cluster/mongo-keyfile:/data/mongo-keyfile privileged: true networks: - mongo arbiter_B_123: image: mongo container_name: mongo_shard_b_123 ports: - 27123:27018 command: /bin/bash -c &quot;chown 999:999 /data/mongo-keyfile &amp;&amp; mongod --keyFile /data/mongo-keyfile --shardsvr --directoryperdb --replSet shard_B --bind_ip 0.0.0.0&quot; volumes: - /home/mongo-cluster/B/123:/data/db - /home/mongo-cluster/mongo-keyfile:/data/mongo-keyfile privileged: true networks: - mongo config_101: image: mongo container_name: mongo_configsvc_101 ports: - 27101:27019 command: /bin/bash -c &quot;chown 999:999 /data/mongo-keyfile &amp;&amp; mongod --keyFile /data/mongo-keyfile --configsvr --directoryperdb --replSet config_servers --bind_ip 0.0.0.0&quot; volumes: - /home/mongo-cluster/config_servers/101:/data/configdb - /home/mongo-cluster/mongo-keyfile:/data/mongo-keyfile networks: - mongo config_102: image: mongo container_name: mongo_configsvc_102 ports: - 27102:27019 command: /bin/bash -c &quot;chown 999:999 /data/mongo-keyfile &amp;&amp; mongod --keyFile /data/mongo-keyfile --configsvr --directoryperdb --replSet config_servers --bind_ip 0.0.0.0&quot; volumes: - /home/mongo-cluster/config_servers/102:/data/configdb - /home/mongo-cluster/mongo-keyfile:/data/mongo-keyfile networks: - mongo route_100: image: mongo container_name: mongo_router_100 ports: - 27017:27017 command: /bin/bash -c &quot;chown 999:999 /data/mongo-keyfile &amp;&amp; mongos --keyFile /data/mongo-keyfile --configdb config_servers/config_101:27019,config_102:27019 --bind_ip 0.0.0.0 --port 27017&quot; volumes: - /home/mongo-cluster/mongo-keyfile:/data/mongo-keyfile depends_on: - config_101 - config_102 networks: - mongonetworks: mongo: driver: bridge ipam: config: - subnet: &quot;174.200.7.0/24&quot; 4、开始构建上传docker-compose.yaml文件到部署机器的/home/mongo-cluster目录下 12cd /home/mongo-clusterdocker-compose up -d 5、查看构建结果12345678910❯ docker ps |grep mongo759bc77ab281 mongo &quot;docker-entrypoint.s…&quot; 17 hours ago Up 17 hours 0.0.0.0:27017-&gt;27017/tcp, :::27017-&gt;27017/tcp mongo_router_1002180cfcf367c mongo &quot;docker-entrypoint.s…&quot; 17 hours ago Up 17 hours 27017/tcp, 0.0.0.0:27121-&gt;27018/tcp, :::27121-&gt;27018/tcp mongo_shard_b_121c5743ce3b5c5 mongo &quot;docker-entrypoint.s…&quot; 17 hours ago Up 17 hours 27017/tcp, 0.0.0.0:27123-&gt;27018/tcp, :::27123-&gt;27018/tcp mongo_shard_b_123664ced56a566 mongo &quot;docker-entrypoint.s…&quot; 17 hours ago Up 17 hours 27017/tcp, 0.0.0.0:27112-&gt;27018/tcp, :::27112-&gt;27018/tcp mongo_shard_a_112ba6825bb0665 mongo &quot;docker-entrypoint.s…&quot; 17 hours ago Up 17 hours 27017/tcp, 0.0.0.0:27113-&gt;27018/tcp, :::27113-&gt;27018/tcp mongo_shard_a_113df6648c5ac09 mongo &quot;docker-entrypoint.s…&quot; 17 hours ago Up 17 hours 27017/tcp, 0.0.0.0:27101-&gt;27019/tcp, :::27101-&gt;27019/tcp mongo_configsvc_1016b385575a5c5 mongo &quot;docker-entrypoint.s…&quot; 17 hours ago Up 17 hours 27017/tcp, 0.0.0.0:27102-&gt;27019/tcp, :::27102-&gt;27019/tcp mongo_configsvc_1021e9d4763b38f mongo &quot;docker-entrypoint.s…&quot; 17 hours ago Up 17 hours 27017/tcp, 0.0.0.0:27111-&gt;27018/tcp, :::27111-&gt;27018/tcp mongo_shard_a_111ede09509a6ed mongo &quot;docker-entrypoint.s…&quot; 17 hours ago Up 17 hours 27017/tcp, 0.0.0.0:27122-&gt;27018/tcp, :::27122-&gt;27018/tcp mongo_shard_b_122 6、将config server加入同一个组1docker exec mongo_configsvc_101 bash -c &quot;echo &#x27;rs.initiate(&#123;_id: \\&quot;config_servers\\&quot;,configsvr: true, members: [&#123; _id : 0, host : \\&quot;mongo_configsvc_101:27019\\&quot; &#125;,&#123; _id : 1, host : \\&quot;mongo_configsvc_102:27019\\&quot; &#125;]&#125;)&#x27; | mongosh --port 27019&quot; 7、将两个shard加入各自的分片组123docker exec mongo_shard_a_111 bash -c &quot;echo &#x27;rs.initiate(&#123;_id: \\&quot;shard_A\\&quot;,members: [&#123; _id : 0, host : \\&quot;mongo_shard_a_111:27018\\&quot; &#125;, &#123; _id : 1, host : \\&quot;mongo_shard_a_112:27018\\&quot; &#125;, &#123; _id : 2, host : \\&quot;mongo_shard_a_113:27018\\&quot; &#125;]&#125;)&#x27; | mongosh --port 27018&quot;docker exec mongo_shard_b_121 bash -c &quot;echo &#x27;rs.initiate(&#123;_id: \\&quot;shard_B\\&quot;,members: [&#123; _id : 0, host : \\&quot;mongo_shard_b_121:27018\\&quot; &#125;, &#123; _id : 1, host : \\&quot;mongo_shard_b_122:27018\\&quot; &#125;, &#123; _id : 2, host : \\&quot;mongo_shard_b_123:27018\\&quot; &#125;]&#125;)&#x27; | mongosh --port 27018&quot; 8、将两个分片加入分片集群123docker exec mongo_router_100 bash -c &quot;echo &#x27;sh.addShard(\\&quot;shard_B/mongo_shard_b_121:27018,mongo_shard_b_122:27018,mongo_shard_b_123:27018\\&quot;)&#x27; | mongosh&quot;docker exec mongo_router_100 bash -c &quot;echo &#x27;sh.addShard(\\&quot;shard_A/mongo_shard_a_111:27018,mongo_shard_a_112:27018,mongo_shard_a_113:27018\\&quot;)&#x27; | mongosh&quot; 三、验证构建123456789101112131415161718192021222324252627282930313233343536373839404142434445docker exec -it mongo_router_100 bashmongosh# 创建管理用户admin = db.getSiblingDB(&quot;admin&quot;)admin.createUser( &#123; user: &quot;admin&quot;, pwd: passwordPrompt(), roles: [ &#123; role: &quot;userAdminAnyDatabase&quot;, db: &quot;admin&quot; &#125; ] &#125;)admin.createUser( &#123; user: &quot;config-reader&quot;, pwd: passwordPrompt(), roles: [ &#123; role: &quot;read&quot;, db: &quot;config&quot; &#125; ] &#125;)[direct: mongos] test&gt; show dbs;admin 112.00 KiBconfig 880.00 KiB[direct: mongos] test&gt; use configswitched to db config[direct: mongos] config&gt; db.getCollection(&#x27;shards&#x27;).find(&#123;&#125;)[ &#123; _id: &#x27;shard_B&#x27;, host: &#x27;shard_B/mongo_shard_b_121:27018,mongo_shard_b_122:27018,mongo_shard_b_123:27018&#x27;, state: 1, topologyTime: Timestamp(&#123; t: 1697192462, i: 3 &#125;) &#125;, &#123; _id: &#x27;shard_A&#x27;, host: &#x27;shard_A/mongo_shard_a_111:27018,mongo_shard_a_112:27018,mongo_shard_a_113:27018&#x27;, state: 1, topologyTime: Timestamp(&#123; t: 1697192491, i: 3 &#125;) &#125;] 执行完看到这些数据，说明构建成功。","categories":[],"tags":[]},{"title":"mongodb-index-text-index","slug":"mongodb-index-text-index","date":"2023-10-11T05:13:48.000Z","updated":"2024-01-18T10:00:03.026Z","comments":false,"path":"2023/10/11/mongodb-index-text-index/","link":"","permalink":"http://example.com/2023/10/11/mongodb-index-text-index/","excerpt":"","text":"MongoDB Text Indexes在MongoDB中，Text索引支持对包含文本内容的字段进行搜索查询。Text索引可以提高对指定单词或者短语的搜索性能。 一个Collection只能有一个Text索引，但是这个索引可以覆盖多个字段。 创建Text索引为Text索引指定默认语言","categories":[{"name":"MongoDB","slug":"MongoDB","permalink":"http://example.com/categories/MongoDB/"},{"name":"Index","slug":"MongoDB/Index","permalink":"http://example.com/categories/MongoDB/Index/"},{"name":"Text Index","slug":"MongoDB/Index/Text-Index","permalink":"http://example.com/categories/MongoDB/Index/Text-Index/"}],"tags":[{"name":"NoSQL","slug":"NoSQL","permalink":"http://example.com/tags/NoSQL/"},{"name":"MongoDB","slug":"MongoDB","permalink":"http://example.com/tags/MongoDB/"},{"name":"Index","slug":"Index","permalink":"http://example.com/tags/Index/"}]},{"title":"distributed_transaction","slug":"distributed-transaction","date":"2023-08-28T02:17:47.000Z","updated":"2024-01-18T10:03:52.981Z","comments":false,"path":"2023/08/28/distributed-transaction/","link":"","permalink":"http://example.com/2023/08/28/distributed-transaction/","excerpt":"","text":"分布式事务什么是分布式事务什么是事务&#x2F;本地事务要清楚什么是分布式事务，首先需要了解什么是事务，或者说本地事务。 我们说的事务通常指的是一组具备A（原子性）、C（一致性）、I（隔离性）、D（持久性）特性的操作： A（原子性）：事务中的操作要么全部成功，要么全部失败； C（一致性）：事务执行完毕之后，数据整体不变，举个经典的转账栗子：A账户中有400软妹币，B账户中也有400软妹币，现在A需要向B转帐200软妹币，此时存在两个操作：1、A账户扣减200软妹币，2、B账户增加200软妹币，而事务的一致性，将会保证事务结束之后，A账户中剩下200软妹币，B账户中此时有600软妹币，软妹币总和还是800，不会出现A账户扣减了200，而B账户未增加200的这种中间状态。 I（隔离性）：多个事务并发执行时不会相互干扰，即一个事务内部的数据对于其它事务来说是隔离的，还是使用上述转账栗子来说的话，那就是扣减A账户200软妹币时，直到这个事务结束之前，其他事务都不知道这个操作。 D（持久性）：指的是一个事务结束之后，这个事务对数据作出的修改是不会因为机器故障或系统故障等原因丢失的。 什么是分布式事务有了对事务&#x2F;本地事务的理解，再来理解分布式事务就很简单了：分布式事务就是由多个本地事务组合而成的事务，它们可以分布在系统的各个地方，而分布式事务就是需要保证这些分布在各个地方的本地事务组合之后仍然具备事务的特性。 分布式事务理论2PC基本介绍2PC也叫两阶段提交，这是一种强一致性的设计理论，2PC引入一个事务协调者的角色来协调管理各个参与者（或者说本地资源）的提交和回滚，二阶段提交分别指的是“准备”和“提交&#x2F;回滚”这两个阶段。 准备阶段：事务协调者会给所有参与者发送准备命令，参与者收到准备命令之后根据情况作出如下操作： 资源足够：返回准备成功信息给事务协调者； 资源不足：返回准备失败信息给事务协调者； 提交&#x2F;回滚阶段：事务协调者根据事务参与者返回的信息来执行提交或者回滚操作： 所有参与者返回准备成功信息：给所有参与者发送提交命令，并在未响应的情况下不断重试； 所有参与者返回准备失败信息：给所有参与者发送回滚命令，并在未响应的情况下不断重试； 当所有事务参与者都返回准备成功之后，事务协调者对所有事务参与者发送提交命令： 只要有一个事务参与者返回准备失败，事务协调者都会对所有事务参与者发送回滚命令： 2PC的弊端 阻塞问题： 在第二个阶段中，事务协调者会等待所有参与者的响应，若有参与者迟迟未响应，那么就会阻塞整个事务过程并且无法释放已被锁定的资源。 协调者单点故障： 2PC高度依赖事务协调者，一旦事务协调者出现故障，那么整个流程都无法继续进行下去。 数据不一致问题： 在第二个阶段，如果在给部分参与者发送提交或回滚命令后协调者出现故障，将导致部分参与者执行了操作，而剩下的参与者未执行操作，导致整体数据出现不一致。 参与者的操作需要幂等： 在第二个阶段，若参与者对协调者的命令响应超时的话，会进行重试，这也就意味着参与者需要实现幂等来应对重复的请求。 总结来说，2PC是一种尽量保证强一致性的分布式事务理论，为了保证强一致性，所以它的操作都是同步阻塞的，而同步阻塞也就意味着会带来较低的执行效率。同时由于全局由事务协调者进行把控，事务协调者容易导致单点故障问题，在一些极端的情况下，可能出现数据不一致的风险。 3PC3PC的出现是为了解决2PC的一些问题，相比于2PC，它在参与者中引入了超时机制，并且新增了一个阶段，使得参与者可以利用这一个阶段统一各自的状态。 3PC包含了三个阶段，分别是准备阶段（CanCommit）、预提交阶段（PreCommit）以及提交阶段（DoCommit）。 总体上来看，就是在2PC之前增加了一个准备阶段，在这个阶段，协调者只是询问参与者自身的情况是否可以进行事务，在这个阶段不会锁定资源，这就能大大降低因为个别参与者资源不足时导致其他参与者资源锁定阻塞的情况发生的概率。 预提交阶段的引入则起到了一个统一状态的作用，如果协调者发来了预提交命令，那么参与者便可以得知此时所有的参与者都已经进入了预提交状态。而对于新选举出来的协调者来说，在刚接任时只需要知道其中一个参与者处于预提交阶段，它就可以直接发送提交命令给所有参与者。 对参与者引入超时机制，则避免了参与者长时间锁定资源阻塞等待的情况： 如果是在等待提交命令，那么等待超时时，参与者就会提交事务，因为到了这一步，大概率是要进行提交操作的； 如果是在等待预提交命令，则该干嘛就干嘛，因为本来就啥都没干，没有锁定任何资源。 分布式事务模式TCC基本介绍TCC采用的补偿机制，其核心思想是：针对每个操作，都要注册一个与其对应的确认和补偿的操作，这里涉及到三个操作，分别是Try，Confirm，Cancel，三个操作的首字母对应TCC： Try：这是暴露给外部服务调用的接口，这个接口将执行资源检测以及资源预留操作； Confirm：在Try操作之后对其进行确认提交，提交之后将会对预留的资源进行真正的扣减； Cancel：Try操作执行错误时将会执行这个操作，在这个操作中将会对预留的资源进行释放。 空取消由于网络原因，在调用Try操作时网络超时而导致Try操作调用失败，继而请求Cancel操作，在请求Cancel操作时网络恢复，Cancel操作请求成功，此时被调用的服务会在没收到Try请求的情况下收到一个Cancel请求，这种情况我们称之为“空取消”。这种情况在复杂的网络下是难以百分百避免的，所以在设计Cancel逻辑时，需要考虑到“空取消”情况。 防悬挂同样由于网络原因，事务协调者在请求Try操作时由于网络原因丢包了，Try操作由于超时而导致事务协调者发送Cancel请求，Cancel请求正常发送到被调用方，形成一个“空取消”操作，而发生了“空取消”，说明此时网络恢复了，之前的Try请求可能通过网络重传等机制在Cancel请求之后被发送到被调用方，此时如果被调用方不拒绝此Try操作的话，会由于之后不会再收到Cancel或者Confirm请而导致锁定的资源不会被释放，这种情况我们称之为“悬挂”，所以我们在设计时，既要允许“空取消”，也要拒绝“空取消”之后的Try请求，避免出现“悬挂”。 优势 保证数据最终一致性； 在业务层实现的事务控制，灵活性高； 劣势 对代码入侵强； 实现难度大，需要根据网络、系统故障等各种原因实现不同的回滚策略； 为了满足一致性要求，Confirm和Cancel接口都必须实现幂等； SAGA基本介绍Saga是一种补偿协议，在Saga模式下，分布式事务内有多个参与者，每个参与者都是一个冲正补偿服务，需要用户根据业务场景实现其正向操作和逆向回滚操作。 分布式事务执行过程中，依次执行各个参与者的正向操作，如果所有正向操作都执行成功，那么分布式事务提交。如果任何一个正向操作执行失败，那么分布式事务会退回去执行前面各参与者的逆向回滚操作，回滚已提交的参与者，使分布式事务回到初始状态。 Saga模式适用于业务流程长且需要保证事务最终一致性的业务系统，Saga模式一阶段就会提交本地事务，无锁，长流程情况下可以保证性能。 事务参与者可以是其它公司的服务、遗留系统的服务或者无法进行改造以提供TCC要求的接口。 同样的，Saga模式也会和TCC模式一样，需要在设计的时候考虑到“空取消”、“防悬挂控制“、”接口幂等“。 优势 一阶段提交本地事务，无锁，性能高； 参与者可以采用事务驱动异步执行，高吞吐； 补偿服务即正向服务的“反向”，易于理解，易于实现。 劣势Saga模式由于一阶段已经提交本地数据库事务，且没有进行“预留”动作，所以不能保证隔离性。 由于Saga不能保证隔离性，所以在某些极端情况下，容易出现“脏写”而导致补偿操作执行困难，针对这种情况，我们可以采取“重试”这样的处理方法继续往前完成这个分布式事务。 同样由于Saga不保证隔离性，所以我们在业务设计的时候需要做到“宁可长款，不可短款”的原则，长款指的是出现差错时站在我方角度钱增多了的情况，短款则是我方钱少了的情况。原因在于我方钱多了，可以采取退款方式将钱补偿给客户，但是我方钱少了的话，这钱就很难再追回。 可靠消息队列最大努力通知","categories":[{"name":"分布式","slug":"分布式","permalink":"http://example.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"分布式事务","slug":"分布式/分布式事务","permalink":"http://example.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/"}],"tags":[{"name":"分布式事务","slug":"分布式事务","permalink":"http://example.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/"}]},{"title":"mysql-index","slug":"mysql-index","date":"2023-08-21T06:46:22.000Z","updated":"2024-01-18T10:00:11.848Z","comments":false,"path":"2023/08/21/mysql-index/","link":"","permalink":"http://example.com/2023/08/21/mysql-index/","excerpt":"","text":"表和索引结构SQL处理过程为SELECT语句创建理想的索引为表连接设计索引","categories":[{"name":"mysql","slug":"mysql","permalink":"http://example.com/categories/mysql/"},{"name":"index","slug":"mysql/index","permalink":"http://example.com/categories/mysql/index/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"http://example.com/tags/Mysql/"}]},{"title":"jvm","slug":"jvm","date":"2023-07-08T02:49:10.000Z","updated":"2023-07-09T08:46:38.246Z","comments":false,"path":"2023/07/08/jvm/","link":"","permalink":"http://example.com/2023/07/08/jvm/","excerpt":"","text":"类加载器JVM自带的类加载器Bootstrap Class Loader 使用C&#x2F;C++语言实现，嵌套在JVM内部； 用来加载Java的核心库（JAVA_HOME&#x2F;jre&#x2F;lib&#x2F;rt.jar、resources.jar或sun.boot.class.path路径下的内容），用于提供JVM自身需要的类； 并不继承自java.lang.ClassLoader，没有父加载器； 加载拓展类加载器和应用程序类加载器，并指定为他们的父类加载器； 出于安全考虑，Bootstrap启动类加载器只加载包名为java、javax、sun等开头的类。 Extension Class Loader Java语言编写，由sun.misc.Launcher$ExtClassLoader实现； 派生于ClassLoader类； 父类加载器为启动类加载器； 从java.ext.dirs系统属性所指定的目录中加载类库，或从JDK的安装目录的jre&#x2F;lib&#x2F;ext子目录下加载类库。如果用户创建的JAR放在此目录下，也会自动由拓展类 System Class Loader Java语言编写，由sun.misc.Launcher$AppClassLoader实现； 派生于ClassLoader类； 父类加载器为拓展类加载器； 它负责加载环境变量classpath或系统属性java.class.path指定路径下的类库； 该类加载器是程序中默认的类加载器，一般来说，Java应用的类都是由它来完成加载； 通过ClassLoader#getSystemClassLoader()方法可以获取到该类加载器。 自定义类加载器为什么要自定义类加载器 隔离加载类，解决全限定类名冲突； 修改类加载的方式； 拓展加载源； 防止源码泄漏。 自定义类加载器步骤 自定义类加载器继承自java.lang.ClassLoader类； 在JDK1.2之前自定义类加载器时，总会去继承ClassLoader类并重写loadClass()方法，从而实现自定义的类加载类，但是在JDK1.2之后，已不再建议用户去覆盖loadClass()方法，而是建议把自定义的类加载逻辑写在findClass()方法中； 在编写自定义类加载器时，如果没有太过于复杂的需求，可以直接继承URLClassLoader类，这样就可以避免自己去编写findClass()方法及其获取字节码流的方式，使自定义类加载器编写更加简洁；","categories":[{"name":"JAVA","slug":"JAVA","permalink":"http://example.com/categories/JAVA/"},{"name":"JVM","slug":"JAVA/JVM","permalink":"http://example.com/categories/JAVA/JVM/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"http://example.com/tags/JVM/"},{"name":"JAVA","slug":"JAVA","permalink":"http://example.com/tags/JAVA/"}]},{"title":"OAuth2.0","slug":"OAuth2-0","date":"2023-07-05T15:06:28.000Z","updated":"2023-07-06T01:23:31.704Z","comments":false,"path":"2023/07/05/OAuth2-0/","link":"","permalink":"http://example.com/2023/07/05/OAuth2-0/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"open-feign","slug":"open-feign","date":"2023-06-29T09:26:37.000Z","updated":"2023-06-29T09:51:56.431Z","comments":false,"path":"2023/06/29/open-feign/","link":"","permalink":"http://example.com/2023/06/29/open-feign/","excerpt":"","text":"简介xxx 常用注解xxx 使用本文将集成Open Feign、Nacos、Spring Cloud Loadbalancer来进行Open Feign的使用介绍。 将会启动两个服务，其中一个是作为服务提供者的订单服务，另一个则是通过Open Feign调用订单服务的消费者服务。 创建服务提供者通过Spring Boot框架启动一个Web服务，并注册到Nacos，这里给出Maven依赖： 1234567891011&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; application.yml配置文件： 12345678910111213spring: application: name: order cloud: nacos: discovery: server-addr: Nacos_Addr username: Nacos_Username password: Nacos_Pwd namespace: Nacos_Namespace group: Nacos_Groupserver: port: 8101 订单服务提供者提供一个简单的接口如下： 12345678@RestController@RequestMapping(&quot;/order&quot;)public class OrderController &#123; @GetMapping(&quot;/get&quot;) public String getOrderService() &#123; return &quot;order&quot;; &#125;&#125; 创建服务消费者通过Spring Boot框架启动一个Web服务，并注册到Nacos，这里给出Maven依赖： 123456789101112131415161718192021&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-loadbalancer&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; application.yml文件： 12345678910111213spring: application: name: open-feign-consumer cloud: nacos: discovery: server-addr: Nacos_Addr username: Nacos_Username password: Nacos_Pwd namespace: Nacos_Namespace group: Nacos_Groupserver: port: 8101 此处请确保Nacos的namespace以及group与订单服务一致。 启动类上加上@EnableFeignClients注解： 1234567@SpringBootApplication@EnableFeignClientspublic class OpenfeignApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(OpenfeignApplication.class); &#125;&#125; Open Feign Client： 12345@FeignClient(&quot;order&quot;) // 需要与订单服务的spring.application.name一致public interface OrderClient &#123; @GetMapping(&quot;/order/get&quot;) // 需要与服务提供者的接口请求路径一致 String getOrderService();&#125; 消费者提供HTTP接口，该接口将通过Open Feign Client调用订单服务提供的接口进行响应： 12345678910@RestController@RequiredArgsConstructorpublic class OrderTestController &#123; private final OrderClient orderClient; @GetMapping(&quot;/feign/order/test&quot;) public String getOrderTest() &#123; System.out.println(&quot;getOrderTest&quot;); return orderClient.getOrderService(); &#125;&#125; 启动服务进行测试将两个服务都启动起来，可以在Nacos上观察到两个服务的注册情况： 使用postman调用open-feign-consumer提供的HTTP接口，可以观察到来自order服务的响应：","categories":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://example.com/categories/Spring-Cloud/"},{"name":"Open Feign","slug":"Spring-Cloud/Open-Feign","permalink":"http://example.com/categories/Spring-Cloud/Open-Feign/"}],"tags":[{"name":"微服务","slug":"微服务","permalink":"http://example.com/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"远程调用","slug":"远程调用","permalink":"http://example.com/tags/%E8%BF%9C%E7%A8%8B%E8%B0%83%E7%94%A8/"}]},{"title":"knife4j-4.1.0-problems","slug":"knife4j-4-1-0-problems","date":"2023-06-27T08:30:15.000Z","updated":"2023-06-27T08:46:42.881Z","comments":false,"path":"2023/06/27/knife4j-4-1-0-problems/","link":"","permalink":"http://example.com/2023/06/27/knife4j-4-1-0-problems/","excerpt":"","text":"在Spring Boot2.7中集成Knife4j 4.1.0是发现GET请求接口调试页面参数展示有如下问题，此处记录一下解决方案: 产生问题的原因4.1.0版本的Knife4j中，OpenAPI依赖版本为1.6.15，这样的版本搭配下，当Controller中的请求参数被@Validated修饰时，便会出现上述问题： 1234@GetMapping(value = &quot;/stores&quot;)public ResultResponse getOrders(@Validated RestRequest request) &#123; return null;&#125; 注意：如果请求参数没有被@Validated修饰，那么在4.1.0版本的Knife4j中，只需要添加如下配置即可解决该问题： 12springdoc: default-flat-param-object: true 解决问题的方法该问题是由错误的版本依赖导致的，那么解决问题的手段便是使用正确的OpenAPI版本，在POM文件中加入如下配置即可，下面的配置将OpenAPI相关依赖的版本从1.6.15升级到了1.7.0： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849&lt;properties&gt; &lt;knife4j.version&gt;4.1.0&lt;/knife4j.version&gt; &lt;springdoc.version&gt;1.7.0&lt;/springdoc.version&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt; &lt;artifactId&gt;knife4j-openapi3-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;$&#123;knife4j.version&#125;&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springdoc&lt;/groupId&gt; &lt;artifactId&gt;springdoc-openapi-common&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springdoc&lt;/groupId&gt; &lt;artifactId&gt;springdoc-openapi-webflux-core&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springdoc&lt;/groupId&gt; &lt;artifactId&gt;springdoc-openapi-webmvc-core&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springdoc&lt;/groupId&gt; &lt;artifactId&gt;springdoc-openapi-ui&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springdoc&lt;/groupId&gt; &lt;artifactId&gt;springdoc-openapi-common&lt;/artifactId&gt; &lt;version&gt;$&#123;springdoc.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springdoc&lt;/groupId&gt; &lt;artifactId&gt;springdoc-openapi-webflux-core&lt;/artifactId&gt; &lt;version&gt;$&#123;springdoc.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springdoc&lt;/groupId&gt; &lt;artifactId&gt;springdoc-openapi-webmvc-core&lt;/artifactId&gt; &lt;version&gt;$&#123;springdoc.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springdoc&lt;/groupId&gt; &lt;artifactId&gt;springdoc-openapi-ui&lt;/artifactId&gt; &lt;version&gt;$&#123;springdoc.version&#125;&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt;","categories":[{"name":"接口文档","slug":"接口文档","permalink":"http://example.com/categories/%E6%8E%A5%E5%8F%A3%E6%96%87%E6%A1%A3/"},{"name":"Knife4j","slug":"接口文档/Knife4j","permalink":"http://example.com/categories/%E6%8E%A5%E5%8F%A3%E6%96%87%E6%A1%A3/Knife4j/"}],"tags":[{"name":"OpenApi","slug":"OpenApi","permalink":"http://example.com/tags/OpenApi/"}]},{"title":"spring-cloud-gateway","slug":"spring-cloud-gateway","date":"2023-06-25T14:53:12.000Z","updated":"2024-01-18T09:59:08.251Z","comments":false,"path":"2023/06/25/spring-cloud-gateway/","link":"","permalink":"http://example.com/2023/06/25/spring-cloud-gateway/","excerpt":"","text":"简介Spring Cloud Gateway是一个构建在Spring生态系统之上的API网关，旨在提供一种简单而有效的方法来将请求路由到API上，同时提供安全、监控、指标和弹性等特性。 主要概念Spring Cloud Gateway包含三个主要概念： 路由：网关的基本构建块，它由一个ID、一个目标URI、一个谓词集合以及一个过滤器集合定义。如果聚集谓词为真，则路由匹配； 谓词：这是一个Java8功能谓词，输入类型为ServerWebExchange，这使得我们可以匹配到HTTP请求中的任何信息，比如请求头和请求参数； 过滤器：使用特定工厂构造出来的GatewayFilter实例，通过过滤器，我们可以在发往下游请求之前或者之后修改请求和响应的内容。 工作方式 客户端向Spring Cloud Gateway发起请求，如果Gateway Handler Mapping确定请求与路由匹配，则将其发送到Gateway Web Handler。这个Handler将通过指定给这个请求的过滤器链来运行这个请求。图中过滤器被虚线分开的原因是过滤器的处理逻辑可以在代理请求被发送之前和之后执行。先执行所有过滤器的“pre”逻辑，之后再创建代理请求，最后再执行所有“post”逻辑。 谓词工厂Spring Cloud Gateway将路由作为Spring WebFlux HandlerMapping基础设施的一部分进行匹配。Spring Cloud Gateway包含许多内置的谓词工厂。这些谓词匹配HTTP请求中的不同属性。我们可以将多个谓词工厂通过And逻辑组合起来。 AfterAfter路由谓词携带一个日期参数，类型为Java中的ZonedDateTime。这个谓词匹配在指定时间之后到来的请求。下面是该谓词的一个示例： 12345678spring: cloud: gateway: routes: - id: after_route uri: https://example.org predicates: - After=2017-01-20T17:42:47.789-07:00[Asia/Shanghai] 该路由只会匹配2017-01-20 17:42:47之后到来的请求。 BeforeBefore路由谓词与After一样，不同点在于该谓词匹配在指定时间之前到来的请求，示例如下： 12345678spring: cloud: gateway: routes: - id: before_route uri: https://example.org predicates: - Before=2017-01-20T17:42:47.789-07:00[Asia/Shanghai] 该路由只会匹配2017-01-20 17:42:47之前到来的请求。 BetweenBetween路由谓词携带两个日期参数，该谓词将匹配在两个日期之间到来的请求，示例如下： 123456789spring: cloud: gateway: routes: - id: between_route uri: https://example.org predicates: - Between=2017-01-20T17:42:47.789-07:00[Asia/Shanghai], 2017-01-21T17:42:47.789-07:00[Asia/Shanghai] 该路由只会匹配2017-01-20 17:42:47与2017-01-21 17:42:47之间到来的请求。 CookieCookie路由谓词携带两个参数，分别是cookie名称和cookie值正则表达式，两个参数由逗号隔开。这个谓词将会匹配到cookie名称与值符合指定参数的请求，示例如下： 12345678spring: cloud: gateway: routes: - id: cookie_route uri: https://example.org predicates: - Cookie=chocolate, ch.p 该示例将匹配携带了名称为chocolate，值为ch.p的cookie的请求。 HeaderHeader路由谓词与Cookie谓词大致相同，不同点在于Header谓词是匹配请求头中的参数，示例如下： 12345678spring: cloud: gateway: routes: - id: header_route uri: https://example.org predicates: - Header=X-Request-Id, \\d+ 该示例将匹配携带了名称为X-Request-Id，值匹配\\d+表达式的请求头的请求。 HostHost路由谓词携带一个参数 Methodxxx Pathxxx Queryxxx RemoteAddrxxx Weightxxx XForwardedxxx 过滤器网关过滤器（Gateway Filters）xxx 全局过滤器（Global Filters）xxx 请求头过滤器（Http Headers Filters）xxx","categories":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://example.com/categories/Spring-Cloud/"},{"name":"Gateway","slug":"Spring-Cloud/Gateway","permalink":"http://example.com/categories/Spring-Cloud/Gateway/"}],"tags":[{"name":"微服务组件","slug":"微服务组件","permalink":"http://example.com/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E7%BB%84%E4%BB%B6/"},{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://example.com/tags/Spring-Cloud/"}]},{"title":"sentinel","slug":"sentinel","date":"2023-05-29T04:00:21.000Z","updated":"2023-05-31T09:50:09.531Z","comments":false,"path":"2023/05/29/sentinel/","link":"","permalink":"http://example.com/2023/05/29/sentinel/","excerpt":"","text":"Sentinel本文绝大部分内容来源于Sentinel官网。 简介随着微服务的流行，服务与服务之间的稳定性变得越来越重要，Sentinel是面向分布式、多语言异构化服务架构的流量治理组件，主要以流量为切入点，从流量路由、流量控制、流量整形、熔断降级、系统自适应过载保护、热点流量防护等多个纬度来帮助开发者保障微服务的稳定性。 Sentinel基本概念资源资源是Sentinel的关键概念，它可以是Java应用程序中的任何内容，例如，由应用程序提供的服务，或由应用程序调用的其它应用提供的服务，甚至可以是一段代码。在接下来的文档中，我们都会用资源来描述代码块。 只要是通过Sentinel API定义的代码，就是资源，能够被Sentinel保护起来。大部分情况下，可以使用方法签名，URL，甚至服务名称作为资源名来标示资源。 规则围绕资源的实时状态设定的规则，可以包括流量控制规则、熔断降级规则以及系统保护规则。所有规则可以动态实时调整。 Sentinel功能和设计理念流量控制流量控制在网络传输中是一个常用概念，它用于调整网络包的发送数据。然而，从系统稳定性角度考虑，在处理请求的速度上，也有非常多的讲究。任意时间到来的请求往往是随机不可控的，而系统的处理能力是有限的。我们需要根据系统的处理能力对流量进行控制。Sentinel作为一个调配器，可以根据需要把随机的请求调整成合适的形状，如下图所示： 流量控制有以下几个角度： 资源的调用关系，例如资源的调用路径，资源和资源之间的关系； 运行指标，例如QPS、线程池、系统负载等； 控制的效果，例如直接限流、冷启动、排队等。 熔断降级什么是熔断降级除了流量控制以外，降低调用链路中的不稳定资源也是Sentinel的使命之一。由于调用关系的复杂性，如果调用链路中的某个资源出现了不稳定，最终会导致请求发生堆积。 如上图所示，在服务调用链路：Service A -&gt; Service G -&gt; Service D 和调用链路Service B -&gt;Service F -&gt;Service D中，由于Service D出现了不稳定情况，导致大量请求堆积在Service D上，而由于Service D响应不积极，所以Service D的所有上游应用都出现了请求阻塞，继续堆积下去或将出现“服务雪崩”，即整个链路上的服务都将不能对外响应。 为了避免这种情况的出现，Sentinel的原则是：当调用链路中某个资源出现不稳定（如：表现为timeout、异常比例升高），则对这个资源的调用进行限制，并让请求快速失败，避免影响到其它的资源，阻止“雪崩”。 熔断降级设计理念Sentinel对这个问题采取了两种手段： 通过并发线程数进行限制 和资源池隔离的方法不同，Sentinel通过限制资源并发线程的数量，来减少不稳定资源对其它资源的影响。这样不但没有线程切换的损耗，也不需要预先分配线程池的大小。当某个资源出现不稳定的情况下，例如响应时间变长，对资源的直接影响就是会造成线程数的逐步堆积。当线程在特定资源上堆积到一定到数量之后，对该资源的新请求就会被拒绝。堆积的线程完成任务后才开始继续接收请求。 通过响应时间对资源进行降级 除了对并发线程数进行控制以外，Sentinel还可以通过响应时间来快速降级不稳定的资源。当依赖的资源出现响应时间过长后，所有对该资源的访问都会被直接拒绝，直到过了指定的时间窗口之后才重新恢复。 系统负载保护Sentinel同时提供系统纬度的自适应保护能力。防止雪崩，是系统防护中重要的一环。当系统负载较高的时候，如果还持续让请求进入，可能会导致系统崩溃，无法响应。在集群环境下，网络负载均衡会把本应这台机器承载的流量转发到其它机器上去。如果这时候其它的机器也处在一个边缘状态的时候，这个增加的流量就会导致这台机器也崩溃，最后导致整个集群不可用。 针对这个情况，Sentinel提供了对应的保护机制，让系统的入口流量和系统的负载达到一个平衡，保证系统在能力范围之内处理最多的请求。 Sentinel是如何工作的Sentinel当主要工作机制如下： 对主流框架提供适配或者显示的API，来定义需要保护的资源，并提供设施对资源进行实时统计和调用链路分析。 根据预设的规则，结合对资源的实时统计信息，对流量进行控制。同时，Sentinel提供开放的接口，方便用户定义和改变规则。 Sentinel提供实时的监控系统，方便用户快速了解目前系统的状态。 资源与规则上述工作机制中有描述到在Sentinel中最重要的两个核心概念：资源与规则，接下来围绕这两个概念进行一些详细说明。 定义资源我们说的资源，可以是任何东西，服务、服务里的方法、甚至是一段代码，使用Sentinel进行资源保护，主要分为几个步骤： 定义资源 定义规则 检验规则是否生效 先把需要保护的资源定义好，之后再配置规则。也可以理解为，只要有了资源，我们就可以在任何时候灵活地定义各种流量控制规则。在编码的时候，只需要考虑这个代码是否需要保护，如果需要保护，就将之定义为一个资源。 规则种类Sentinel的所有规则都可以在内存中动态地查询和修改，修改之后立即生效。同时Sentinel也提供相关API以供用户定制自己的规则策略。 Sentinel支持以下几种规则：流量控制规则、熔断降级规则、系统保护规则、来源访问控制规则和热点参数规则。 流量控制规则（FlowRule） 一个流量控制规则由如下属性定义： 属性 说明 默认值 resource 资源名，也就是流控规则作用的对象 count 限流阈值 grade 限流阈值类型，QPS或线程数 QPS limitApp 流控针对的调用来源 default，表示不区分调用来源 strategy 调用关系限流策略：直接、链路、关联 直接 controlBehavior 流控效果：直接拒绝、排队等待、慢启动，不支持按调用关系限流 直接拒绝 同一个资源可以同时有多个限流规则。 熔断降级规则（DegradeRule） 一个熔断降级规则包含下面几个重要的属性： 属性 说明 默认值 resource 资源名，即规则的作用对象 grade 熔断策略，支持慢调用比例&#x2F;异常比例&#x2F;异常数策略 慢调用比例 count 慢调用比例模式下为慢调用临界RT（超出该值计为慢调用）;异常比例&#x2F;异常数模式下为对应的阈值 timewindow 熔断时长，单位为s minRequestAmount 熔断触发最小请求数，请求数小于该值时即使异常比率超出阈值也不会熔断。 5 statIntervalMs 统计时长（单位为ms） 1000ms slowRatioThreshold 慢调用比例阈值，仅慢调用比例模式有效 同一个资源可以同时有多个降级规则。 系统保护规则（SystemRule） Sentinel系统自适应限流从整体纬度对应用入口流量进行控制，结合应用的Load、CPU使用率、总体平均RT、入口QPS和并发线程数等几个纬度的监控指标，通过自适应的流控策略，让系统的入口流量和系统的负载达到一个平衡，让系统尽可能跑在最大吞吐量的同时保证系统整体的稳定性。 系统规则包含下面几个重要的属性 属性 说明 默认值 highestSystemLoad load1触发值，用于触发自适应控制阶段 -1（不生效） avgRt 所有入口流量的平均响应时间 -1（不生效） maxThread 入口流量的最大并发数 -1（不生效） qps 所有入口资源的QPS -1（不生效） highestCpuUsage 当前系统的CPU使用率（0.0 - 1.0） -1（不生效） 访问控制规则（AuthorityRule） 很多时候，我们需要根据调用方来限制资源是否通过，这时候可以使用Sentinel对访问控制（黑白名单）的功能。黑白名单根据资源的请求来源限制资源是否通过，若配置白名单则只有请求来源位于白名单内时才可以通过；若配置黑名单则请求来源位于黑名单时不通过，其余的请求通过。 授权规则，即黑白名单规则，非常简单，主要有以下配置项： resource：资源名，即规则的作用对象 limitApp：对应的黑&#x2F;白名单，不同origin用,分隔，如：AppA,AppB strategy：限制模式，AUTHORITY_WHITE为白名单， AUTHORITY_BLACK为黑名单，默认为白名单 热点规则（ParamFlowRule） 热点即经常访问的数据，很多时候我们希望统计某个热点数据中访问频次最高的Top K数据，并对其访问进行限制。热点规则有以下几个属性： 属性 说明 默认值 resource 资源名 count 限流阈值 grade 限流模式 QPS durationInSec 统计窗口时间长度 1s controlBehavior 流控效果，支持快速失败和匀速排队模式 快速失败 maxQueueingTimeMs 最大排队等待时长，仅在匀速排队模式生效 0ms paramIdx 热点参数索引 paramFlowItemList 参数例外项，可以针对指定的参数单独设置限流阈值，不受前面count阈值的限制 clusterMode 是否是集群参数流控规则 false clusterConfig 集群流控相关配置 安装Sentinel控制台Docker安装 查找Sentinel镜像 123456docker search sentinelNAME DESCRIPTION STARS OFFICIAL AUTOMATEDbladex/sentinel-dashboard Alibaba Cloud Sentinel Dashboard (阿里巴巴流… 79bitnami/redis-sentinel Bitnami Docker Image for Redis Sentinel 45 [OK]sentinelofficial/sentinel-vpn-node 7 拉取镜像 1docker pull bladex/sentinel-dashboard 启动容器 1docker run -d --name sentinel -p 8858:8858 -e AUTH_USERNAME=user -e AUTH_PASSWORD=pwd bladex/sentinel-dashboard 使用集成Spring Cloud 引入依赖 12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt; &lt;version&gt;2.2.9.RELEASE&lt;/version&gt;&lt;/dependency&gt; 接入控制台，在application.yml中写入如下配置： 12345678spring: application: name: Sentinel-App cloud: sentinel: transport: port: 8179 dashboard: yuanmenglv:8858 port：在应用所在机器的8179端口启动一个HTTP Server，用于接收Sentinel控制台推送过来的数据。 dashboard：连接的Sentinel控制台地址 流量控制概述限流的直接表现是在执行Entry nodeA &#x3D; SphU.entry(“资源名字”)的时候抛出FlowException。FlowException是BlockException的子类，用户可以步骤BlockException来自定义被限流之后的处理逻辑。 同一个资源可以对应多条限流规则，FlowSlot会对该资源的所有限流规则一次遍历，直到有规则触发限流或者所有规则遍历完毕。 一条限流规则主要由下面几个因素组成，我们可以组合这些元素来实现不同的限流效果： resource：资源名，即限流规则作用对象 count：限流阈值 grade：限流阈值类型，QPS或线程数 strategy：根据调用关系选择策略 基于QPS&#x2F;并发数的流量控制流量控制主要有两种统计类型，一种是统计线程数，另外一种则是统计QPS。类型由FlowRule.grade字段来定义。其中，0代表根据并发数量来限流，1代表根据QPS来进行流量控制。其中线程数、QPS值都是由StatisticSlot实时统计获取的。 可以通过下面的命令查看实时统计信息： 1curl http://localhost:8719/cnode?id=resourceName 输出内容格式如下： 12idx id thread pass blocked success total aRt 1m-pass 1m-block 1m-all exception 2 /endpoint4 0 0.0 0.0 0.0 0.0 0.0 13 0 13 0.0 其中： thread：当前处理该资源的线程数 pass：代表一秒内到来的请求 blocked：代表一秒内被流量控制的请求数量 success：代表一秒内成功处理完的请求 total：代表一秒内到来的请求以及被阻止的请求总和 aRt：代表一秒内该资源的平均响应时间 1m-pass：一分钟内到来的请求 1m-block：一分钟内被阻止的请求 1m-all：一分钟内到来的请求和阻止的请求的总和 exception：一秒内业务本身异常的总和 并发线程数流量控制线程数限流用于保护业务线程不被耗尽。例如，当应用所依赖的下游应用由于某种原因导致服务不稳定、响应延迟增加，对于调用者来说，意味着吞吐量下降和更多的线程数占用，极端情况下甚至导致线程池耗尽。为应对高线程占用的情况，业内有使用隔离的方案，比如通过不同业务逻辑使用不同的线程池来隔离业务自身之间的资源争抢，或者使用信号量来控制同时请求的个数。这种隔离方案虽然能够控制线程数量，单无法控制请求排队时间，当请求过多时排队也是无益的，直接拒绝能够迅速降低系统压力。Sentinel线程数限流不负责创建和管理线程池，而是简单统计当前请求上下文的线程个数，如果超出阈值，新的请求会被立即拒绝。 QPS流量控制当QPS超过某个阈值的时候，则采取措施进行流量控制。流量控制的手段包括下面3种，对应FlowRule中的controlBehavior字段： 直接拒绝 直接拒绝（RuleConstant.CONTROL_BEHAVIOR_DEFAULT）。该方式是默认的流量控制方式，当QPS超过任意规则的阈值后，新的请求会被立即拒绝，拒绝方式为抛出FlowException。这种方式适用于对系统能力确切已知的情况下，比如通过压测确定了系统的准确水位时。 冷启动 冷启动（RuleConstant.CONTROL_BEHAVIOR_WARM_UP）。该方式主要用于系统长期处于低水位的情况下，当流量突然增加时，直接把系统拉升到高水位可能瞬间把系统压垮。通过“冷启动”，让通过的流量缓慢增加，在一定时间内逐渐增加到阈值上限，给冷系统一个预热到时间，避免冷系统被压垮的情况。 通常冷启动的过程系统允许通过的QPS曲线如下图所示： 匀速器 匀速器（RuleConstant.CONTROL_BEHAVIOR_RATE_LIMITER）这种方式严格控制了请求通过的间隔时间，也即是让请求以均匀的速度通过，对应的是漏桶算法，该方式的作用如下图所示： 这种方式主要用于处理间隔性突发的流量，例如消息队列。想象一下这样的场景，在某一秒有大量的请求到来，而接下来的几秒则处于空闲状态，我们希望系统能够在接下来的空闲期间逐渐处理这些请求，而不是在第一秒直接拒绝多余的请求。 基于调用关系的流量控制调用关系包括调用方、被调用方；方法有可能会调用其他方法，形成一个调用链路的层次关系。Sentinel通过NodeSelectorSlot建立不同资源间的调用关系，并且通过ClusterNodeBuilderSlot记录每个资源的实时统计信息。 有了调用链路的统计信息，我们可以衍生出多种流量统计手段。 根据调用方限流ContextUtil.enter(resourceName, origin) 方法中的 origin 参数标明了调用方身份。这些信息会在 ClusterBuilderSlot 中被统计。可通过以下命令来展示不同的调用方对同一个资源的调用数据： 1curl http://localhost:8719/origin?id=nodeA 调用数据示例： 1234id: nodeAidx origin threadNum passedQps blockedQps totalQps aRt 1m-passed 1m-blocked 1m-total 1 caller1 0 0 0 0 0 0 0 02 caller2 0 0 0 0 0 0 0 0 上面这个命令展示了资源名为 nodeA 的资源被两个不同的调用方调用的统计。 限流规则中的 limitApp 字段用于根据调用方进行流量控制。该字段的值有以下三种选项，分别对应不同的场景： default：表示不区分调用者，来自任何调用者的请求都将进行限流统计。如果这个资源名的调用总和超过了这条规则定义的阈值，则触发限流。 &#123;some_origin_name&#125;：表示针对特定的调用者，只有来自这个调用者的请求才会进行流量控制。例如 NodeA 配置了一条针对调用者caller1的规则，那么当且仅当来自 caller1 对 NodeA 的请求才会触发流量控制。 other：表示针对除 &#123;some_origin_name&#125; 以外的其余调用方的流量进行流量控制。例如，资源NodeA配置了一条针对调用者 caller1 的限流规则，同时又配置了一条调用者为 other 的规则，那么任意来自非 caller1 对 NodeA 的调用，都不能超过 other 这条规则定义的阈值。 同一个资源名可以配置多条规则，规则的生效顺序为：**{some_origin_name} &gt; other &gt; default** 根据调用链路入口限流：链路限流NodeSelectorSlot中记录了资源之间的调用链路，这些资源通过调用关系，相互之间构成一棵调用树，这棵树的根节点是一个名字为machine-root的虚拟节点，调用链的入口都是这个虚节点的子节点。 一棵典型的调用树如下图所示： 1234567 machine-root / \\ / \\ Entrance1 Entrance2 / \\ / \\DefaultNode(nodeA) DefaultNode(nodeA) 上图中来自入口Entrance1和Entrance2的请求都调用到了资源NodeA，Sentinel允许只根据某个入口的统计信息对资源限流。比如我们可以设置FlowRule.strategy为RuleConstant.CHAIN，同时设置FlowRule.ref_identity为Entrance1来表示只有从入口Entrance1的调用才会记录到NodeA的限流统计当中，而对来自Entrance2的调用漠不关心。 具有关系的资源流量控制：关联流量控制当两个资源之间存在资源争抢或者依赖关系时，这两个资源便具有了关联。比如对数据库同一个字段的读操作和写操作存在争抢，读的速度过高会影响写的速度，写的速度过高会影响读的速度。如果放任读写操作争抢资源，则争抢本身带来的开销会降低整体的吞吐量。可使用关联限流来避免具有关联关系的资源之间过度的争抢，举例来说，read_db和write_db这两个资源分别代表数据库读写，我们可以给read_db设置限流规则来达到写优先的目的：设置FlowRule.strategy为Ruleconstant.RELATE，同时设置FlowRule.ref_identity为write_db，这样当写库操作过于频繁时，读数据的请求会被限流。 熔断降级概述对于熔断的叙述前文已经足够详细了，熔断的主要目的就是暂时与不稳定服务断开，避免局部的不稳定因素导致整体的雪崩。熔断降级作为保护自身的手段，通常在客户端（调用端）进行配置。 熔断策略Sentinel提供了以下几种熔断策略： 慢调用比例（SLOW_REQUEST_RATIO）：选择以慢调用比例作为阈值，需要设置允许的慢调用RT（最大响应时间），请求的响应时间大于该值则统计为慢调用。当单位统计时长内请求数目大于设置的最小请求数目，并且慢调用的比例大于阈值，则接下来的熔断时长内的请求会自动被熔断。经过熔断时长后熔断器会进入探测恢复状态，若接下来的一个请求响应时间小于设置的慢调用RT则结束熔断，若大于设置的慢调用RT则会再次被熔断。 在Sentinel控制台对应的设置页面为： 异常比例（ERROR_RATIO）：当单位统计时长内请求数目大于设置的最小请求数目，并且异常的比例大于阈值，则接下来的熔断时长内请求会自动被熔断。经过熔断时长后熔断器会进入探测恢复状态，若接下来的一个请求成功完成则熔断结束，否则会再次被熔断。 在Sentinel控制台对应的设置页面为： 异常数（ERROR_COUNT）：当单位统计时长内的异常数目超过阈值之后会自动进行熔断。经过熔断时长后熔断器会进入探测恢复状态，若接下来的一个请求成功完成则结束熔断，否则会再次被熔断。 在Sentinel控制台对应的设置页面为： 系统自适应保护xxx 背景xxx 系统规则xxx 原理xxx 集群流量控制xxx 介绍xxx 模块结构xxx 集群流控规则xxx 规则xxx 配置方式xxx 集群限流客户端xxx 集群限流服务端xxx 启动方式xxx … 网关流量控制xxx Spring Cloud Gatewayxxx 热点参数限流xxx 来源访问控制xxx 注解支持xxx 动态规则拓展xxx Nacos将规则持久化到Nacos中。 引入依赖 12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba.csp&lt;/groupId&gt; &lt;artifactId&gt;sentinel-datasource-nacos&lt;/artifactId&gt; &lt;version&gt;1.8.5&lt;/version&gt;&lt;/dependency&gt; 从Nacos中加载规则 1234567Properties properties = new Properties();properties.put(PropertyKeyConst.SERVER_ADDR , serverAddr);properties.put(PropertyKeyConst.NAMESPACE , namespace);properties.put(PropertyKeyConst.USERNAME, userName);properties.put(PropertyKeyConst.PASSWORD, password);ReadableDataSource&lt;String, List&lt;FlowRule&gt;&gt; flowRuleDataSource = new NacosDataSource&lt;&gt;(properties, groupId, dataId,source -&gt; JSON.parseObject(source, new TypeReference&lt;&gt;() &#123;&#125;));FlowRuleManager.register2Property(flowRuleDataSource.getProperty()); 基本原理概述在Sentinel里面，所有的资源都对应一个资源名称以及一个Entry。Entry可以通过对主流框架的适配自动创建，也可以通过注解的方式或调用API显示创建；每一个Entry创建的时候，同时也会创建一系列功能插槽（slot chain）。这些插槽有不同的职责，例如： NodeSelectorSlot：负责收集资源的路径，并将这些资源的调用路径以树状结构存储起来，用于根据调用路径来限流降价； ClusterBuilderSlot：用于存储资源的统计信息以及调用者信息，例如该资源的RT、QPS、thread count等，这些信息将用作多纬度限流、降级的依据； StatisticSlot：用于记录，统计不同纬度的runtime指标监控信息； FlowSlot：用于根据预设的限流规则以及前面slot统计的状态来进行流量控制； AuthoritySlot：根据配置的黑白名单和调用来源信息来做黑白名单控制； DegradeSlot：统计统计信息和预设的规则来做熔断降级； SystemSlot：通过系统的状态，例如load1等，来控制总的入口流量。 NodeSelectorSlot这个slot主要负责收集资源的路径，并将这些资源的调用路径，以树状结构存储起来，用于根据调用路径来限流降级。 ClusterBuilderSlot这个slot用于构建资源的ClusterNode以及调用来源节点。ClusterNode保持资源运行统计信息（响应时间、QPS、block数目、线程数、异常数等）以及原始调用者统计信息列表。来源调用者的名字由ContextUtil.enter(contextName, origin)中的origin标记。可以通过如下命令查看某个资源不同调用者的访情况： 1curl http://localhost:8719/origin?id=caller StatisticSlot这个slot是Sentinel的核心功能插槽之一，用于统计实时的调用数据。 clusterNode：资源唯一标识的ClusterNode的runtime统计； origin：根据来自不同调用者的统计信息； defaultnode：根据上下文条目名称和资源ID的runtime统计； 入口的统计。 Sentinel底层采用高性能的滑动窗口数据结构LeapArray来统计实时的秒级指标数据，可以很好地支撑写多于读的高并发场景。 FlowSlot这个slot主要根据预设的流控规则以及资源的统计信息，按照固定的次序，使规则依次生效。如果一个资源对应多条流控规则，则会根据如下次序依次检验，直到全部生效或者有一个规则生效为止： 指定应用生效的规则，即针对调用方限流； 调用方为other的规则； 调用方为default的规则； DegradeSlot这个slot主要针对资源的平均响应时间（RT）以及异常比率来决定资源是否在接下来的时间内被自动熔断掉。 SystemSlot这个slot会根据当前系统的整体情况，对入口资源的调用进行动态分配。其原理是让入口的流量和当前系统的预计容量达到一个动态平衡。","categories":[{"name":"服务限流","slug":"服务限流","permalink":"http://example.com/categories/%E6%9C%8D%E5%8A%A1%E9%99%90%E6%B5%81/"},{"name":"Sentinel","slug":"服务限流/Sentinel","permalink":"http://example.com/categories/%E6%9C%8D%E5%8A%A1%E9%99%90%E6%B5%81/Sentinel/"}],"tags":[{"name":"服务限流","slug":"服务限流","permalink":"http://example.com/tags/%E6%9C%8D%E5%8A%A1%E9%99%90%E6%B5%81/"},{"name":"服务熔断","slug":"服务熔断","permalink":"http://example.com/tags/%E6%9C%8D%E5%8A%A1%E7%86%94%E6%96%AD/"},{"name":"Sentinel","slug":"Sentinel","permalink":"http://example.com/tags/Sentinel/"}]},{"title":"nacos","slug":"nacos","date":"2023-05-28T04:25:56.000Z","updated":"2023-05-29T03:34:42.199Z","comments":false,"path":"2023/05/28/nacos/","link":"","permalink":"http://example.com/2023/05/28/nacos/","excerpt":"","text":"Nacos简介Nacos&#x2F;nɑ:kəʊs&#x2F;是Dynamic Naming and Configuration Service的首字母简称，一个更易于构建云原生应用的动态服务发现、配置管理和服务管理平台。 Nacos致力于帮助用户发现、配置和管理微服务。Nacos提供了一组简单易用的特性集，帮助用户快速实现动态服务发现、服务配置、服务元数据以及流量管理。 Nacos帮助用户更敏捷和容易地构建、交付和管理微服务平台。Nacos是构建以“服务”为中心的现代应用架构的服务基础设施。 服务是Nacos世界的一等公民，Nacos支持几乎所有主流类型的“服务”的发现、配置和管理： Kubernetes Service gRPC &amp; Dubbo RPC Service Spring Cloud RESTful Service Nacos的关键特性包括： 服务发现和服务健康检测 Nacos支持基于DNS和基于RPC的服务发现。服务提供者使用原生SDK、OpenAPI或一个独立的Agent TODO注册Service之后，服务消费者可以使用DNS TODO或HTTP&amp;API查找和发现服务。 Nacos提供对服务的实时的健康检查，阻止向不健康的主机或服务实例发送请求。Nacos支持传输层（PING或TCP）和应用层（HTTP、MySQL或用户自定义）的健康检查。对于复杂的云环境和网络拓扑环境中服务的健康检查，Nacos提供了Agent上报模式和服务端主动检测两种健康检查模式。Nacos还提供了统一的健康检查仪表盘，帮助用户根据健康状态管理服务的可用性及流量。 动态配置服务 动态配置服务可以让用户以中心化、外部化和动态化的方式管理所有环境的应用配置和服务配置。 动态配置消除了配置变更时重新部署应用和服务的需要，让配置管理变得更加高效和敏捷。 配置中心化管理让实现无状态服务变得更简单，让服务按需弹性拓展变得更容易。 Nacos提供了一个简洁易用的UI帮助用户管理所有的服务和应用的配置。Nacos还提供包括配置版本跟踪、金丝雀发布、一键回滚配置以及客户端配置更新状态追踪在内的一系列开箱即用的配置管理特性，帮助用户更安全地在生产环境中管理配置变更和降低配置变更带来的风险。 动态DNS服务 动态DNS服务支持权重路由，让用户更容易地实现中间层负载均衡、更灵活的路由策略、流量控制以及数据中心内网的简单DNS解析服务。动态DNS服务还能让与用户更容易地实现以DNS协议为基础的服务发现，以帮助用户消除耦合到厂商私有服务发现API上的风险。 Nacos提供了一些简单的DNS APIs TODO帮助用户管理服务的关联域名和可用的IP:PORT列表。 服务及其元数据管理 Nacos能让用户从微服务平台建设的视角管理数据中心的所有服务及元数据，包括管理服务的描述、生命周期、服务的静态依赖分析、服务的健康状态、服务的流量管理、路由及安全策略、服务的SLA以及最首要的metrics统计数据。 安装 拉取Nacos镜像 准备Nacos数据库 启动Nacos容器 使用配置管理使用SDK 引入依赖 12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba.nacos&lt;/groupId&gt; &lt;artifactId&gt;nacos-client&lt;/artifactId&gt; &lt;version&gt;2.1.0&lt;/version&gt;&lt;/dependency&gt; 获取配置 123456789101112131415161718public class NacosConfigClient &#123; public static void main(String[] args) throws NacosException &#123; String serverAddr = &quot;host:port&quot;; String dataId = &quot;dataId&quot;; String group = &quot;group&quot;; String userName = &quot;userName&quot;; String password = &quot;password&quot;; String namespace = &quot;namespace&quot;; Properties properties = new Properties(); properties.put(PropertyKeyConst.SERVER_ADDR, serverAddr); properties.put(PropertyKeyConst.USERNAME, userName); properties.put(PropertyKeyConst.PASSWORD, password); properties.put(PropertyKeyConst.NAMESPACE , namespace); ConfigService configService = NacosFactory.createConfigService(properties); String config = configService.getConfig(dataId, group, 5000); System.out.println(&quot;config = &quot; + config); &#125;&#125; ConfigService接口中封装了操作配置相关API，对配置的相应操作调用相应接口即可，此处不做详细展示了，列出ConfigService接口定义： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133/** * Config Service Interface. * * @author Nacos */public interface ConfigService &#123; /** * Get config. * * @param dataId dataId * @param group group * @param timeoutMs read timeout * @return config value * @throws NacosException NacosException */ String getConfig(String dataId, String group, long timeoutMs) throws NacosException; /** * Get config and register Listener. * * &lt;p&gt;If you want to pull it yourself when the program starts to get the configuration for the first time, and the * registered Listener is used for future configuration updates, you can keep the original code unchanged, just add * the system parameter: enableRemoteSyncConfig = &quot;true&quot; ( But there is network overhead); therefore we recommend * that you use this interface directly * * @param dataId dataId * @param group group * @param timeoutMs read timeout * @param listener &#123;@link Listener&#125; * @return config value * @throws NacosException NacosException */ String getConfigAndSignListener(String dataId, String group, long timeoutMs, Listener listener) throws NacosException; /** * Add a listener to the configuration, after the server modified the configuration, the client will use the * incoming listener callback. Recommended asynchronous processing, the application can implement the getExecutor * method in the ManagerListener, provide a thread pool of execution. If not provided, use the main thread callback, May * block other configurations or be blocked by other configurations. * * @param dataId dataId * @param group group * @param listener listener * @throws NacosException NacosException */ void addListener(String dataId, String group, Listener listener) throws NacosException; /** * Publish config. * * @param dataId dataId * @param group group * @param content content * @return Whether publish * @throws NacosException NacosException */ boolean publishConfig(String dataId, String group, String content) throws NacosException; /** * Publish config. * * @param dataId dataId * @param group group * @param content content * @param type config type &#123;@link ConfigType&#125; * @return Whether publish * @throws NacosException NacosException */ boolean publishConfig(String dataId, String group, String content, String type) throws NacosException; /** * Cas Publish config. * * @param dataId dataId * @param group group * @param content content * @param casMd5 casMd5 prev content&#x27;s md5 to cas. * @return Whether publish * @throws NacosException NacosException */ boolean publishConfigCas(String dataId, String group, String content, String casMd5) throws NacosException; /** * Cas Publish config. * * @param dataId dataId * @param group group * @param content content * @param casMd5 casMd5 prev content&#x27;s md5 to cas. * @param type config type &#123;@link ConfigType&#125; * @return Whether publish * @throws NacosException NacosException */ boolean publishConfigCas(String dataId, String group, String content, String casMd5, String type) throws NacosException; /** * Remove config. * * @param dataId dataId * @param group group * @return whether remove * @throws NacosException NacosException */ boolean removeConfig(String dataId, String group) throws NacosException; /** * Remove listener. * * @param dataId dataId * @param group group * @param listener listener */ void removeListener(String dataId, String group, Listener listener); /** * Get server status. * * @return whether health */ String getServerStatus(); /** * Shutdown the resource service. * * @throws NacosException exception. */ void shutDown() throws NacosException;&#125; Spring Cloud引入依赖12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt; &lt;version&gt;2.2.9.RELEASE&lt;/version&gt;&lt;/dependency&gt; 提供配置123456789spring: cloud: nacos: config: server-addr: ip:port username: user password: password group: group namespace: namespace 提供如上配置之后，Spring Cloud应用会使用user和password在部署在ip:port的nacos中进行身份认证，认证通过后，从namespace下的group中获取DataID中的配置数据，上面的配置中并未提供出DataID相关信息，此时Spring Cloud应用会根据下文中介绍的DataID默认拉取机制拉取配置数据。 DataID默认拉取优先级Spring Cloud中，Nacos会默认以spring.application.name、spring.profiles.active、spring.cloud.nacos.config.file-extension属性的值为基础来选择DataID拉取配置数据，接下来以配置这三个属性为如下值为例子来进行说明： spring.application.name：test spring.profiles.active：dev spring.cloud.nacos.config.file-extension：properties DataId拉取优先级从高到低如下： spring.application.name-spring.profiles.active.spring.cloud.nacos.config.file-extension：如test-dev.properties。 spring.application.name.spring.cloud.nacos.config.file-extension：如test.properties。 spring.application.name：如test。 即优先级：test-dev.properties &gt; test.properties &gt; test。 拉取指定DataID以上是根据Spring相关配置信息默认拉取配置数据，如果我们需要拉取指定DataID该怎么办呢？spring-cloud-starter-alibaba-nacos-config包提供了如下两个配置来让我们拉取指定DataID，只需要在application.yml或bootstrap.yml等配置文件中指定这两个值即可： spring.cloud.nacos.config.shared-configs spring.cloud.nacos.config.extension-configs 123456789101112spring: cloud: nacos: config: shared-configs: - dataId: common group: test refresh: true extension-configs: - data-id: extension group: test refresh: true 这两个属性的值都是一个数组，可以指定多个DataID。 那么两者的区别是什么呢？下面简要总结两点区别： 概念不同：shared-configs用于引入共享配置，即在多个应用间拓展的配置，而extension-configs用于引入本应用的拓展配置，作用域为本应用。 优先级：extension-configs优先级大于shared-configs，即同一个配置，会优先从extension-configs中指定的DataID中获取。 DataID总体拉取优先级： test-dev.properties &gt; test.properties &gt; test &gt;extension-configs &gt; shared-configs。 配置监听在某些业务场景下，我们需要监听DataID中配置的变化，当配置信息出现变化时执行特定的业务逻辑，Nacos提供了配置监听功能： 12345678910111213141516171819202122232425public class NacosConfigClient &#123; public static void main(String[] args) throws NacosException &#123; String serverAddr = &quot;host:port&quot;; String dataId = &quot;dataId&quot;; String group = &quot;group&quot;; String userName = &quot;userName&quot;; String password = &quot;password&quot;; String namespace = &quot;namespace&quot;; Properties properties = new Properties(); properties.put(PropertyKeyConst.SERVER_ADDR, serverAddr); properties.put(PropertyKeyConst.USERNAME, userName); properties.put(PropertyKeyConst.PASSWORD, password); properties.put(PropertyKeyConst.NAMESPACE , namespace); ConfigService configService = NacosFactory.createConfigService(properties); configService.addListener(dataId, group, new Listener() &#123; public Executor getExecutor() &#123; return null; &#125; public void receiveConfigInfo(final String configInfo) &#123; // 当配置信息出现变化时执行特定逻辑 System.out.println(&quot;configInfo = &quot; + configInfo); &#125; &#125;); &#125;&#125; 注册发现服务注册使用SDK 引入依赖 12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba.nacos&lt;/groupId&gt; &lt;artifactId&gt;nacos-client&lt;/artifactId&gt; &lt;version&gt;2.1.0&lt;/version&gt;&lt;/dependency&gt; 样例代码 12345678910111213141516171819202122232425262728293031323334353637public class NacosRegisterClient &#123; public static void main(String[] args) throws NacosException &#123; String serverAddr = &quot;host:port&quot;; String userName = &quot;userName&quot;; String password = &quot;password&quot;; String namespace = &quot;namespace&quot;; Properties properties = new Properties(); properties.put(PropertyKeyConst.SERVER_ADDR, serverAddr); properties.put(PropertyKeyConst.USERNAME, userName); properties.put(PropertyKeyConst.PASSWORD, password); properties.put(PropertyKeyConst.NAMESPACE , namespace); NamingService namingService = NamingFactory.createNamingService(properties); NamingService namingService1 = NamingFactory.createNamingService(properties); NamingService namingService2 = NamingFactory.createNamingService(properties); NamingService namingService3 = NamingFactory.createNamingService(properties); NamingService namingService4 = NamingFactory.createNamingService(properties); namingService.registerInstance(&quot;user&quot;, &quot;dev&quot;, &quot;11.11.11.11&quot;, 8888); namingService1.registerInstance(&quot;user&quot;, &quot;prod&quot;, &quot;11.11.11.12&quot;, 8888, &quot;BJ&quot;); namingService2.registerInstance(&quot;user&quot;, &quot;prod&quot;, &quot;11.11.11.13&quot;, 8888, &quot;GD&quot;); namingService3.registerInstance(&quot;user&quot;, &quot;prod&quot;, &quot;11.11.11.14&quot;, 8888, &quot;GD&quot;); Instance instance = new Instance(); instance.setIp(&quot;11.11.11.15&quot;); instance.setPort(8888); instance.setWeight(2); instance.setHealthy(true); instance.setClusterName(&quot;GD&quot;); instance.setServiceName(&quot;user&quot;); instance.setEnabled(true); instance.setEphemeral(true); namingService4.registerInstance(&quot;user&quot;,&quot;prod&quot;, instance); // 不让main线程被kill while (true)&#123;&#125; &#125;&#125; NamingService Nacos在NamingService接口中封装了对服务注册相关操作，该接口中方法较多，就不粘贴代码了，请自行查看源码。 12package com.alibaba.nacos.api.naming;public interface NamingService &#123;&#125; Spring Cloud 引入依赖 12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;version&gt;2.2.9.RELEASE&lt;/version&gt;&lt;/dependency&gt; 提供配置 1234567891011spring: application: name: application-name cloud: nacos: discovery: server-addr: ip:port username: user password: password group: group namespace: namespace 提供如上配置之后，Spring Cloud应用会使用user和password在部署在ip:port的nacos中进行身份认证，认证通过后，会以application-name作为服务名将自己的相关信息注册在namespace的group下。 服务发现使用SDK 引入依赖 12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba.nacos&lt;/groupId&gt; &lt;artifactId&gt;nacos-client&lt;/artifactId&gt; &lt;version&gt;2.1.0&lt;/version&gt;&lt;/dependency&gt; 样例代码 123456789101112131415161718192021222324public class NacosDiscoveryClient &#123; public static void main(String[] args) throws NacosException &#123; String serverAddr = &quot;yuanmenglv:8848&quot;; String userName = &quot;nacos&quot;; String password = &quot;LB1126520.&quot;; String namespace = &quot;849ae32c-40e5-4b68-a342-7c27cce9bb69&quot;; String serviceName = &quot;user&quot;; String groupName = &quot;prod&quot;; Properties properties = new Properties(); properties.put(PropertyKeyConst.SERVER_ADDR, serverAddr); properties.put(PropertyKeyConst.USERNAME, userName); properties.put(PropertyKeyConst.PASSWORD, password); properties.put(PropertyKeyConst.NAMESPACE , namespace); NamingService namingService = NacosFactory.createNamingService(properties); for (final Instance userService : namingService.getAllInstances(serviceName, groupName)) &#123; System.out.println(&quot;userService = &quot; + userService); &#125; System.out.println(&quot;select one&quot;); for (int i = 0; i &lt; 10; i++) &#123; Instance instance = namingService.selectOneHealthyInstance(serviceName, groupName); System.out.println(instance); &#125; &#125;&#125; 由以上代码可以看出，服务发现相关接口也是封装在NamingService接口中，所以NamingService接口中封装了服务注册和服务发现所需的所有API。 Spring Cloudxxxxxx 架构原理 Nacos中的一致性协议Raft（CP）Distro（AP）","categories":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://example.com/categories/Spring-Cloud/"},{"name":"Discovery","slug":"Spring-Cloud/Discovery","permalink":"http://example.com/categories/Spring-Cloud/Discovery/"}],"tags":[{"name":"微服务组件","slug":"微服务组件","permalink":"http://example.com/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E7%BB%84%E4%BB%B6/"},{"name":"注册发现","slug":"注册发现","permalink":"http://example.com/tags/%E6%B3%A8%E5%86%8C%E5%8F%91%E7%8E%B0/"},{"name":"Nacos","slug":"Nacos","permalink":"http://example.com/tags/Nacos/"}]},{"title":"swagger","slug":"swagger","date":"2023-05-24T03:53:57.000Z","updated":"2023-05-24T06:34:14.993Z","comments":false,"path":"2023/05/24/swagger/","link":"","permalink":"http://example.com/2023/05/24/swagger/","excerpt":"","text":"OpenAPI规范（OAS）简介OpenAPI规范（OAS）为HTTP API定义了一个与语言无关的标准接口，它允许人类或计算机在不接触源码、文档或通过网络检查的情况下发现和了解服务的能力。如果定义得当，消费者可以通过少量的逻辑实现来理解并且与远程服务交互。 一个OpenAPI定义可以被文档生成工具使用来展示API，或者被代码生成工具来生成各种编程语言的服务器、客户端或者测试工具，以及许多其它方面的用处。 定义接下来介绍一些OpenAPI的定义以便于理解。 OpenAPI文档（OpenAPI Document） 一个单独或复合的资源，用来定义或描述一个API或者API的元素。一个OpenAPI文档必须至少包含一个paths字段、一个components字段或者一个webhooks字段。 路径模板化（Path Templating） 媒体类型（Media Types） HTTP状态码（HTTP Status Codes） 规范Swagger2注解替换为Swagger3 @Api -&gt; @Tag @ApiIngnore -&gt; @Parameter(hidden = true) or @Operation(hidden = true) or @Hidden @ApiImplicitParam -&gt; @Parameter @ApiImplicitParams -&gt; @Parameters @ApiModel -&gt; @Schema @ApiModelProperty -&gt; @Schema @ApiModelProperty -&gt; @Schema @ApiModelProperty(hidden = true) -&gt; @Schema(accessMode = READ_ONLY) @ApiOperation(value = &quot;foo&quot;, notes = &quot;bar&quot;) -&gt; @Operation(summary = &quot;foo&quot;, description=&quot;bar&quot;) @ApiParam -&gt; @Parameter @ApiResponse(code = 404, message = &quot;foo&quot;) -&gt; @ApiResponse(responseCode = &quot;404&quot;, description = &quot;foo&quot;)","categories":[{"name":"接口文档","slug":"接口文档","permalink":"http://example.com/categories/%E6%8E%A5%E5%8F%A3%E6%96%87%E6%A1%A3/"},{"name":"Swagger","slug":"接口文档/Swagger","permalink":"http://example.com/categories/%E6%8E%A5%E5%8F%A3%E6%96%87%E6%A1%A3/Swagger/"}],"tags":[{"name":"Api Doc","slug":"Api-Doc","permalink":"http://example.com/tags/Api-Doc/"}]},{"title":"jwt","slug":"jwt","date":"2023-05-17T14:42:03.000Z","updated":"2023-05-17T15:35:36.090Z","comments":false,"path":"2023/05/17/jwt/","link":"","permalink":"http://example.com/2023/05/17/jwt/","excerpt":"","text":"什么是JWTJWT全称为JSON WEB TOKEN，是一个开放标准（FRC 7519），它定义了一种紧凑且自包含的方式在各方之间以JSON对象的形式安全地传输信息。此信息是可以被验证和信任的，因为它是数字签名的。JWT可以使用密钥（HMAC算法）或RSA等公钥&#x2F;私钥算法进行签名。 JWT应用场景JWT有如下常见场景： 授权：用户登陆之后的每个请求都携带JWT，从而允许用户访问该令牌允许的资源。单点登录是当今广泛应用JWT的一项功能，因为它开销很小并且可以在不同的域中轻松使用。 信息交换：JWT是在各方之间安全传输信息的好方法，因为可以对JWT进行签名，所以可以确定发件人就是已知的那个人。此外，还可以通过头部信息和有效负载来计算签名，这样就可以验证内容有没有被篡改。 JWT结构JWT由以点（.）分隔的三部分组成，它们分别是： 头部信息 有效负载 签名 因此JWT通常如下所示： xxxxxxxx.yyyyyyyyyy.zzzzzzzzz 头部信息（Header）头部信息通常由两部分组成：签名算法和令牌类型，例如： 1234&#123; &quot;alg&quot;: &quot;HS256&quot;, &quot;typ&quot;: &quot;JWT&quot;&#125; 最后，将这个JSON对象通过Base64URL算法转成字符串作为Header。 有效负载（Payload）有效负载也是一个JSON对象，用来存放实际需要传递的数据。JWT规定了7个官方字段： iss（Issuer）：签发JWT人 exp（Expiration time）：过期时间 sub（Subject）：主题 aud（Audience）：受众 nbf（Not Before）：生效时间 iat（Issued At）：签发时间 jti（JWT ID）：编号 除了官方字段，还可以在这个部分定义私有字段，如下： 12345&#123; &quot;sub&quot;: &quot;123456789&quot;, &quot;name&quot;: &quot;Ryan&quot;, &quot;admin&quot;: false&#125; JWT默认是不加密的，任何人都可以读到，所以不要把秘密信息放在这个部分。 最后，将这个JSON对象通过Base64URL算法转成字符串作为Payload。 签名（Signature）签名部分是对签名两个部分的签名，防止数据篡改。 这里需要用到一个密钥（secret），这个密钥只能服务器知道，不能泄漏，然后使用Header中指定的签名算法（默认为HMAC SHA256），按照如下公式产生签名： 1HMACSHA256(base64UrlEncode(header)+&quot;.&quot;+base64UrlEncode(payload), secret) 算出签名之后，把Header、Payload、Signature三个部分通过.分隔之后返回给用户。 Base64UrlHeader和Payload部分都是使用Base64Url算法来做串型化，这个算法跟Base64算法基本类似，不同之处在于：JWT作为一个令牌，有些场合下会放URL，Base64有三个字符+、/和=，这在URL里面有特殊含义，需要被替换掉：=被省略，+替换成-，/替换成_，这个就是Base64Url算法。 JWT工作机制","categories":[{"name":"jwt","slug":"jwt","permalink":"http://example.com/categories/jwt/"}],"tags":[{"name":"jwt","slug":"jwt","permalink":"http://example.com/tags/jwt/"}]},{"title":"mysql-mvcc","slug":"mysql-mvcc","date":"2023-05-10T08:52:13.000Z","updated":"2023-08-21T06:48:11.600Z","comments":false,"path":"2023/05/10/mysql-mvcc/","link":"","permalink":"http://example.com/2023/05/10/mysql-mvcc/","excerpt":"","text":"MVCC（多版本并发控制）","categories":[{"name":"mysql","slug":"mysql","permalink":"http://example.com/categories/mysql/"},{"name":"MVCC","slug":"mysql/MVCC","permalink":"http://example.com/categories/mysql/MVCC/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"http://example.com/tags/Mysql/"},{"name":"MVCC","slug":"MVCC","permalink":"http://example.com/tags/MVCC/"}]},{"title":"mysql-logs","slug":"mysql-logs","date":"2023-05-09T02:39:54.000Z","updated":"2023-05-17T07:11:51.635Z","comments":false,"path":"2023/05/09/mysql-logs/","link":"","permalink":"http://example.com/2023/05/09/mysql-logs/","excerpt":"","text":"Mysql中日志文件总结日志文件是Mysql数据库中的重要组成部分，通过不同的日志文件记录了Mysql数据库运行期间发生的各种变化。通过Mysql中的各种日志文件，我们可以看到Mysql运行期间客户端连接、SQL执行情况等信息以及在Mysql崩溃后进行数据的恢复等操作。 Mysql中存在6种日志文件分别是： 错误日志（error log） 慢查询日志（slow query log） 一般查询日志（general log） 二进制日志（binlog） 重做日志（redo log） 回滚日志（undo log） 接下来对Mysql中的各个日志文件进行介绍。 错误日志错误日志对Mysql的启动、运行以及关闭等过程进行了记录。当Mysql出现问题时，首先应该查询该日志文件以定位问题。该文件不仅记录了所有的错误日志，也记录了所有的警告信息。我们可以通过如下命令来查找该文件的位置： 1show variables like &#x27;log_error&#x27;; 慢查询日志慢查询日志记录了运行时间超过指定阈值的SQL，我们可以通过查看慢查询日志找出性能不佳的SQL进行优化。 开启慢查询慢查询日志默认是未开启的，可以通过如下命令查看慢查询日志开关状态： 1show variables like &#x27;slow_query_log&#x27;; 默认状态下将会返回如下结果表示未开启慢查询日志： 12345+----------------+-------+| Variable_name | Value |+----------------+-------+| slow_query_log | OFF |+----------------+-------+ 通过如下Mysql指令可以开启慢日志查询： 1set global slow_query_log=1 开启后再次查看慢查询日志开关状态： 1234567show variables like &#x27;slow_query_log&#x27;;+----------------+-------+| Variable_name | Value |+----------------+-------+| slow_query_log | ON |+----------------+-------+ 设定慢查询阈值开启慢查询日志记录后，那么什么样的查询会被记录到慢查询日志中呢？ 我们可以通过如下命令查看慢查询阈值，当SQL的运行时间超过阈值后，便会被记录到慢查询日志中： 1show variables like &#x27;long_query_time&#x27;; 得到如下结果： 12345+-----------------+-----------+| Variable_name | Value |+-----------------+-----------+| long_query_time | 10.000000 |+-----------------+-----------+ 可以看出，默认的慢查询阈值为10（单位为秒）。 通过如下命令可以设置该阈值大小； 1set global long_query_time=2; 退出会话重新登陆后再次查看慢查询阈值，发现已经生效。 记录未使用索引SQL除了执行时间超过阈值的SQL会被记录到慢查询日志之外，还有一种SQL也会被记录到慢查询日志中，那就是未使用索引的SQL，该配置默认也是未打开的，我们可以通过如下命令查看该配置开启状态： 1show variables like &#x27;log_queries_not_using_indexes&#x27;; 查询结果如下： 1234| Variable_name | Value |+-------------------------------+-------+| log_queries_not_using_indexes | OFF |+-------------------------------+-------+ 当前表示该配置没有打开，未使用到索引的查询SQL不会被记录到慢查询日志中。 通过如下指令可以开启记录未使用索引的SQL： 1set global log_queries_not_using_indexes=1; 开启该配置后，所有未使用到索引的查询SQL都会被记录到慢查询日志中，这将导致慢查询日志越来越大，为了避免慢查询日志越来越膨胀，MySQL5.6.5版本开始提供了一个参数：log_throttle_queries_not_using_indexes。该参数用于设置每分钟允许记录到慢查询日志中未使用索引的SQL语句，默认值为0，表示没有限制，通过如下命令可以改变该参数的值： 1set global log_throttle_queries_not_using_indexes=60; 如上设置了每分钟允许记录60条未使用索引的查询SQL到慢查询日志中； 设定慢查询输出方式在默认情况下，Mysql以文件的方式来存储慢查询日志，通过如下命令可以查看： 1show variables like &#x27;log_output&#x27;; 结果如下： 12345+---------------+-------+| Variable_name | Value |+---------------+-------+| log_output | FILE |+---------------+-------+ 慢查询日志文件位置通过如下命令查看： 1show variables like &#x27;slow_query_log_file&#x27;; MySQL 5.1之后可以将慢查询日志修改为存储到Mysql的mysql.slow_log表中： 1set global log_output=&#x27;TABLE&#x27;; 执行如下查询之后，可以在mysql.slow_log表中查询到该SQL（注意：此时慢查询日志阈值为10（秒））： 12select sleep(14);select * from mysql.slow_log; 查询日志查询日志记录了所有对MySQL数据库请求对信息，无论这些请求是否得到了正确的执行。默认情况下配置项是关闭的，可以通过如下命令开启： 1set global general_log=1; 查看是否开启： 1show variables like &#x27;general_log&#x27;; 结果： 12345+---------------+-------+| Variable_name | Value |+---------------+-------+| general_log | ON |+---------------+-------+ 配置项打开之后，查询日志将存储于mysql.general_log表中，执行如下语句可进行查询： 1select * from mysql.general_log; 要关闭记录查询日志可执行如下命令： 1set global general_log=0; 二进制日志简介二进制日志记录了对MySQL数据库内数据执行更改的所有操作。但是不包括SELECT和SHOW这类操作，因为这类操作并没有对数据本身进行修改。需要注意的是，如果某个修改操作并没有导致数据库数据发生变化，这个操作也有可能被写入二进制日志。 作用二进制日志主要有如下几种作用： 恢复：某些数据的恢复需要二进制日志，例如，在一个数据库通过全备份文件恢复后，可以通过二进制日志进行point-in-time恢复。 复制：原理与恢复类似，通过复制和执行二进制日志使一台远程的MySQL数据库与一台MySQL数据库进行实时同步。 审计：用户可以通过二进制日志中的信息来进行审计，判断是否有对数据库进行注入的攻击。 开启二进制日志二进制日志默认情况下是关闭的，执行如下命令可以查看启动状态： 1show variables like &#x27;log_bin&#x27;; 执行结果如下，当前表示关闭状态： 12345+---------------+--------+| Variable_name | Value |+---------------+--------+| log_bin | OFF |+---------------+--------+ 如果是关闭状态的话，需要修改MySQL的配置文件才能开启，配置文件目录一般为：&#x2F;etc&#x2F;mysql&#x2F;mysql.conf.d&#x2F;mysqld.cnf，在[mysqld]下添加如下配置内容： 123[mysqld]log-bin=/var/lib/mysql/mysql-binserver-id=1 参数说明： log-bin：指定二进制日志文件位置 server-id：MySQL5.7以上版本需要指定，否则启动将会报错。 重启MySQL服务后再次查看，可以看到已经开启记录二进制日志： 12345+---------------+-------+| Variable_name | Value |+---------------+-------+| log_bin | ON |+---------------+-------+ 查看开启二进制日志后，可以通过如下方式查看二进制日志文件： 1show binlog events; 执行结果如下： 1234567891011+------------------+-----+----------------+-----------+-------------+---------------------------------------+| Log_name | Pos | Event_type | Server_id | End_log_pos | Info |+------------------+-----+----------------+-----------+-------------+---------------------------------------+| mysql-bin.000001 | 4 | Format_desc | 1 | 123 | Server ver: 5.7.41-log, Binlog ver: 4 || mysql-bin.000001 | 123 | Previous_gtids | 1 | 154 | || mysql-bin.000001 | 154 | Anonymous_Gtid | 1 | 219 | SET @@SESSION.GTID_NEXT= &#x27;ANONYMOUS&#x27; || mysql-bin.000001 | 219 | Query | 1 | 307 | BEGIN || mysql-bin.000001 | 307 | Table_map | 1 | 373 | table_id: 118 (mountain_sea.TAG) || mysql-bin.000001 | 373 | Write_rows | 1 | 446 | table_id: 118 flags: STMT_END_F || mysql-bin.000001 | 446 | Xid | 1 | 477 | COMMIT /* xid=3276 */ |+------------------+-----+----------------+-----------+-------------+---------------------------------------+ 结果中各项参数说明如下： Log_name：二进制日志文件名称。 Pos：当前事件的开始位置，每个事件都占用固定的字节大小，结束位置减去Pos，就是这个事件占用的字节数。 Event_type：表示事件的类型。 Server_id：表示产生这个事件的MySQL server_id，通过设置my.cnf中的server-id选项进行配置。 End_log_pos：下一个事件开始位置。 Info：包含事件的具体信息。 当存在多个二进制日志文件时，可以查看指定二进制日志文件： 1show binlog events in &#x27;mysql-bin.000001&#x27;; 参数说明二进制日志有许多参数来控制其行为，接下来对其参数进行一个简单介绍。 通过如下命令可以查看二进制日志相关参数： 12show variables like &#x27;%binlog%&#x27;;show variables like &#x27;%log_bin%&#x27;; 该指令可以查询出如下参数： binlog_cache_size binlog_checksum binlog_direct_non_transactional_updates binlog_error_action binlog_format binlog_group_commit_sync_delay binlog_group_commit_sync_no_delay_count binlog_gtid_simple_recovery binlog_max_flush_queue_time binlog_order_commits binlog_row_image binlog_rows_query_log_events binlog_stmt_cache_size binlog_transaction_dependency_history_size binlog_transaction_dependency_tracking innodb_api_enable_binlog innodb_locks_unsafe_for_binlog log_statements_unsafe_for_binlog max_binlog_cache_size max_binlog_size max_binlog_stmt_cache_size sync_binlog log_bin log_bin_basename log_bin_index log_bin_trust_function_creators log_bin_use_v1_row_events sql_log_bin 接下来对其中重要的参数进行介绍： log_bin：用于开启binlog功能，并设置二进制日志文件存储位置，该参数为只读属性，无法在运行期间修改，需要修改配置文件之后重启生效。 log_bin_index：指定二进制日志索引文件所在位置。 max_binlog_cache_size：binlog使用的内存最大尺寸。 binlog_cache_size：binlog使用的内存大小。 通过二进制日志恢复数据重做日志（Redo Log）重做日志是什么InnoDB引擎是以页为单位来管理存储空间的，在访问一页的数据时，会先将这页数据从磁盘上加载出来缓存到内存中的Buffer Poll中，之后对该页数据的操作都是在Buffer Poll中进行，有了Buffer Poll，CPU和磁盘之间的速率鸿沟得到优化，系统整体性能得到提高。 Buffer Poll中被更新了的数据页，我们称之为脏页，脏页会在之后以一定的速率被刷进磁盘，但同时这也就意味着，如果在刷写磁盘之前发生了系统崩溃或机器宕机等灾难时，Buffer Poll中的数据将会丢失。 而事务的持久性要求事务只要一提交，这个事务对数据库所做的更改便不能丢失，为了解决这个问题，InnoDB引擎的事务采用了WAL（Write-Ahead Logging），这种技术的思想就是先写日志，再写磁盘，只有日志写入成功，才算事务提交成功。这里的日志就是Redo Log。当发生宕机且数据未刷到磁盘时，可以通过Redo Log来恢复，保证ACID中的D。 为什么要有重做日志需要重做日志的理由之一上文已经给出了介绍：保证事务持久化特性。 另外一个重要原因便是：提高IO效率。 我们知道，MySQL是以页为单位来组织数据的，一页的大小为16KB。如果某次执行SQL只是修改了一个字节，那么为了持久化这个修改，我们就必须将整页刷进磁盘，这种问题我们称之为写放大，这样的IO方式显然效率低下。 其次，执行一条语句可能会修改多个页的数据，这些页可能不是相邻的页，那么在持久化这些页的时候，就会出现随机IO，随机IO的效率低于顺序IO。 而有了重做日志之后，能避免出现写放大和随机IO问题： 重做日志按照顺序记录下了对数据的更新操作，这也就意味着重做日志中存储的都是数据变更操作，与脏页相比，其不会存在写放大问题，因为重做日志中存储的都是需要写磁盘的数据。 再者，对重做日志的写都是顺序写，自然也就不存在随机IO问题。 因此，通过重做日志，IO效率整体得到了提升。 深入理解重做日志重做日志组成重做日志可以简单分为以下两个部分： 缓冲 缓冲是易失的，是MySQL服务器启动时向操作系统申请的一片连续内存空间，称为Redo Log Buffer。这片内存空间被分为多个连续的Redo Log Block，一个Redo Log Block占用512字节。 Redo Log Buffer的大小由参数innodb_log_buffer_size设置，默认为16M，最大值是4096M，最小值是1M。可由以下命令查看该参数： 1show variables like &#x27;innodb_log_buffer_size&#x27;; 文件 重做日志文件是持久的，保存在硬盘上，保存在MySQL的数据目录（&#x2F;var&#x2F;lib&#x2F;mysql）下，日志文件名如下： ib_logfile0 ib_logfile1 重做日志整体执行流程 将事务需要操作的数据从磁盘加载到数据缓冲区； 将对数据的操作生成一条重做日志写入重做日志缓冲区； 根据设置的刷盘策略将重做日志缓冲区的数据写入磁盘； 根据设置的策略将数据缓冲区中的脏数据刷进磁盘中。 重做日志刷盘策略重做日志并不是直接写入到磁盘的，而是会先将重做日志数据写进Redo Log Buffer，之后再以一定的频率将数据从Redo Log Buffer写进磁盘，这里的写磁盘频率，就是将要介绍的重做日志刷盘策略。 在介绍重做日志刷盘策略之前，先简单介绍一下操作系统的页缓存机制（Page Cache）：页缓存机制是现代操作系统为了提高磁盘IO速率而做的一个优化，在真正写入磁盘之前，会将要写的数据先缓存在内存中，缓冲区中攒够数据（或到一定时间，这是操作系统可配置的）之后，再统一写进磁盘。（大概就是这样一个意思，得其意即可）。 由操作系统的页缓存机制可知，在数据真正写入磁盘之前，会有一个缓冲期，如果此时宕机的话，将会导致数据丢失。针对这种情况，InnoDB给出了innodb_flush_log_at_trx_commit参数来控制事务提交时如何将Redo Log Buffer中的日志数据落盘到Redo Log File中，它提供了三种策略： 0：每次事务提交时不进行刷盘操作，而是交给master thread每1s进行一次重做日志刷盘，因此如果Mysql实例崩溃，最多丢失1s数据。 1：每次事务提交时都进行刷盘操作，而且一定是要将数据写进磁盘文件中。这种策略下数据最安全，因为它保证了事务提交成功前重做日志数据一定写进了磁盘中，但是性能也是最差的，因为需要每次事务提交都需要进行磁盘IO。 2：每次事务提交时都将Redo Log Buffer内容写进操作系统的页缓存（Page Cache）中，之后再由操作系统决定什么时候将数据写进磁盘。这种策略下，Mysql实例崩溃不会导致数据丢失，数据只会在操作系统崩溃或宕机时才会丢失。 各策略下重做日志刷盘情况如图所示： 日常情况下，建议改参数设置为1，这样数据最安全，在系统高峰期时再将改参数设置为2，以提高Mysql性能。 查询改参数当前值可以使用如下命令： 1show variables like &#x27;innodb_flush_log_at_trx_commit&#x27;; 设置改参数值可以使用如下命令： 1set global innodb_flush_log_at_trx_commit=1; 写入Redo Log Buffer的过程Mysql把对底层数据页的一次原子访问的过程称为Mini-Transaction，简称mtr，一个mtr可以包含多条Redo日志，在进行崩溃恢复时，这多条的Redo日志将作为一组不可分割的整体来执行。 一个事务可以包含多条语句，一个语句可以包含多个mtr，一个mtr可以包含一组Redo日志。 因为一个mtr下的一组Redo日志是一个不可分割的整体，所以在mtr执行过程中，并不是每生成一条Redo日志，就将这条日志写进Redo Log Buffer中，而是先将这个mtr产生的重做日志先暂存到一个地方，等整个mtr执行完毕之后，再将这组重做日志整体写进Redo Log Buffer中。 由于重做日志是在一个mtr执行完毕之后整体写入Redo Log Buffer中的，所以当多个事务交替进行时，多个事务下的mtr产生的重做日志会按顺序交替存储在Redo Log Buffer中。 日志文件先介绍一下日志文件相关的参数。 innodb_log_group_home_dir：指定Redo Log文件组所在的位置，默认值为“.&#x2F;”； innodb_log_files_in_group：指定Redo Log File的个数，默认值为2，最大值为100，文件命名方式为：ib_logfile0，ib_logfile1； innodb_flush_log_at_trx_commit：控制Redo Log刷新到磁盘的策略，默认为1； innodb_log_file_size：单个Redo Log文件大小，默认值为48M，最大值为512G，这里说的最大值指的是整个Redo Log文件组的文件大小之和。 由以上参数可以看出，重做日志组中日志文件数量和大小是固定的，那么日志文件写满之后改怎么办呢？ Mysql使用了checkpoint技术来解决这个问题，接下来简单介绍一下checkpoint技术。 在checkpoint技术中，将一组重做日志文件组成一个逻辑上的环型循环队列，通过write pos和checkpoint两个指针来循环利用重做日志文件写入日志： write pos：当前可写日志位置，每次写入后往后推移 checkpoint：当前已擦除位置，每次写入后往后推移 如下图所示，write pos和checkpoint都按顺时针方向往后推移，checkpoint到write pos之间的区域表示的是未检查区域，如果Mysql从崩溃中恢复，需要执行该区域中的日志。write pos到checkpoint之间的区域是可写区域，该区域内的数据已经写进了Mysql数据文件中，是可以被覆盖的。 随着Mysql的运行，执行的数据修改语句越来越多，write pos将会不停向前推进，直到追上checkpoint，此时可写区域已经耗尽，无法再写入新的Redo Log，需要Mysql停下来清理一下脏数据，并推进checkpoint以获得可写区域来写入新的Redo Log。 回滚日志","categories":[{"name":"mysql","slug":"mysql","permalink":"http://example.com/categories/mysql/"},{"name":"log file","slug":"mysql/log-file","permalink":"http://example.com/categories/mysql/log-file/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"http://example.com/tags/Mysql/"},{"name":"日志文件","slug":"日志文件","permalink":"http://example.com/tags/%E6%97%A5%E5%BF%97%E6%96%87%E4%BB%B6/"}]},{"title":"test-comments","slug":"test-comments","date":"2023-04-19T14:17:59.000Z","updated":"2023-04-24T10:55:22.687Z","comments":false,"path":"2023/04/19/test-comments/","link":"","permalink":"http://example.com/2023/04/19/test-comments/","excerpt":"","text":"不知道github push有没有生效啊 Test again test thirdly 18:55","categories":[],"tags":[{"name":"Test","slug":"Test","permalink":"http://example.com/tags/Test/"}]},{"title":"mysql-arch","slug":"mysql-arch","date":"2023-04-19T12:49:47.000Z","updated":"2023-05-11T05:35:30.527Z","comments":true,"path":"2023/04/19/mysql-arch/","link":"","permalink":"http://example.com/2023/04/19/mysql-arch/","excerpt":"","text":"this is a article for archtecture of mysql","categories":[{"name":"Database","slug":"Database","permalink":"http://example.com/categories/Database/"},{"name":"Mysql","slug":"Database/Mysql","permalink":"http://example.com/categories/Database/Mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://example.com/tags/mysql/"},{"name":"architecture","slug":"architecture","permalink":"http://example.com/tags/architecture/"}]},{"title":"Hello World","slug":"hello-world","date":"2023-04-19T10:40:08.930Z","updated":"2023-04-19T10:40:08.930Z","comments":false,"path":"2023/04/19/hello-world/","link":"","permalink":"http://example.com/2023/04/19/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}],"categories":[{"name":"Redis","slug":"Redis","permalink":"http://example.com/categories/Redis/"},{"name":"Basic","slug":"Redis/Basic","permalink":"http://example.com/categories/Redis/Basic/"},{"name":"中间件","slug":"中间件","permalink":"http://example.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"搜索","slug":"中间件/搜索","permalink":"http://example.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2/"},{"name":"ES","slug":"中间件/搜索/ES","permalink":"http://example.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%90%9C%E7%B4%A2/ES/"},{"name":"代码库","slug":"代码库","permalink":"http://example.com/categories/%E4%BB%A3%E7%A0%81%E5%BA%93/"},{"name":"Java","slug":"代码库/Java","permalink":"http://example.com/categories/%E4%BB%A3%E7%A0%81%E5%BA%93/Java/"},{"name":"回复邮件","slug":"代码库/Java/回复邮件","permalink":"http://example.com/categories/%E4%BB%A3%E7%A0%81%E5%BA%93/Java/%E5%9B%9E%E5%A4%8D%E9%82%AE%E4%BB%B6/"},{"name":"消息队列","slug":"消息队列","permalink":"http://example.com/categories/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"消息队列比对","slug":"消息队列/消息队列比对","permalink":"http://example.com/categories/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E6%AF%94%E5%AF%B9/"},{"name":"通信协议","slug":"通信协议","permalink":"http://example.com/categories/%E9%80%9A%E4%BF%A1%E5%8D%8F%E8%AE%AE/"},{"name":"Websocket","slug":"通信协议/Websocket","permalink":"http://example.com/categories/%E9%80%9A%E4%BF%A1%E5%8D%8F%E8%AE%AE/Websocket/"},{"name":"分布式共识算法","slug":"分布式共识算法","permalink":"http://example.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E5%85%B1%E8%AF%86%E7%AE%97%E6%B3%95/"},{"name":"Raft","slug":"分布式共识算法/Raft","permalink":"http://example.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E5%85%B1%E8%AF%86%E7%AE%97%E6%B3%95/Raft/"},{"name":"领导选举","slug":"分布式共识算法/Raft/领导选举","permalink":"http://example.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E5%85%B1%E8%AF%86%E7%AE%97%E6%B3%95/Raft/%E9%A2%86%E5%AF%BC%E9%80%89%E4%B8%BE/"},{"name":"MongoDB","slug":"MongoDB","permalink":"http://example.com/categories/MongoDB/"},{"name":"Index","slug":"MongoDB/Index","permalink":"http://example.com/categories/MongoDB/Index/"},{"name":"Text Index","slug":"MongoDB/Index/Text-Index","permalink":"http://example.com/categories/MongoDB/Index/Text-Index/"},{"name":"分布式","slug":"分布式","permalink":"http://example.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"分布式事务","slug":"分布式/分布式事务","permalink":"http://example.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/"},{"name":"mysql","slug":"mysql","permalink":"http://example.com/categories/mysql/"},{"name":"index","slug":"mysql/index","permalink":"http://example.com/categories/mysql/index/"},{"name":"JAVA","slug":"JAVA","permalink":"http://example.com/categories/JAVA/"},{"name":"JVM","slug":"JAVA/JVM","permalink":"http://example.com/categories/JAVA/JVM/"},{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://example.com/categories/Spring-Cloud/"},{"name":"Open Feign","slug":"Spring-Cloud/Open-Feign","permalink":"http://example.com/categories/Spring-Cloud/Open-Feign/"},{"name":"接口文档","slug":"接口文档","permalink":"http://example.com/categories/%E6%8E%A5%E5%8F%A3%E6%96%87%E6%A1%A3/"},{"name":"Knife4j","slug":"接口文档/Knife4j","permalink":"http://example.com/categories/%E6%8E%A5%E5%8F%A3%E6%96%87%E6%A1%A3/Knife4j/"},{"name":"Gateway","slug":"Spring-Cloud/Gateway","permalink":"http://example.com/categories/Spring-Cloud/Gateway/"},{"name":"服务限流","slug":"服务限流","permalink":"http://example.com/categories/%E6%9C%8D%E5%8A%A1%E9%99%90%E6%B5%81/"},{"name":"Sentinel","slug":"服务限流/Sentinel","permalink":"http://example.com/categories/%E6%9C%8D%E5%8A%A1%E9%99%90%E6%B5%81/Sentinel/"},{"name":"Discovery","slug":"Spring-Cloud/Discovery","permalink":"http://example.com/categories/Spring-Cloud/Discovery/"},{"name":"Swagger","slug":"接口文档/Swagger","permalink":"http://example.com/categories/%E6%8E%A5%E5%8F%A3%E6%96%87%E6%A1%A3/Swagger/"},{"name":"jwt","slug":"jwt","permalink":"http://example.com/categories/jwt/"},{"name":"MVCC","slug":"mysql/MVCC","permalink":"http://example.com/categories/mysql/MVCC/"},{"name":"log file","slug":"mysql/log-file","permalink":"http://example.com/categories/mysql/log-file/"},{"name":"Database","slug":"Database","permalink":"http://example.com/categories/Database/"},{"name":"Mysql","slug":"Database/Mysql","permalink":"http://example.com/categories/Database/Mysql/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://example.com/tags/Redis/"},{"name":"DataStructure","slug":"DataStructure","permalink":"http://example.com/tags/DataStructure/"},{"name":"ES","slug":"ES","permalink":"http://example.com/tags/ES/"},{"name":"代码库","slug":"代码库","permalink":"http://example.com/tags/%E4%BB%A3%E7%A0%81%E5%BA%93/"},{"name":"消息队列","slug":"消息队列","permalink":"http://example.com/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"Websocket","slug":"Websocket","permalink":"http://example.com/tags/Websocket/"},{"name":"全双工通信","slug":"全双工通信","permalink":"http://example.com/tags/%E5%85%A8%E5%8F%8C%E5%B7%A5%E9%80%9A%E4%BF%A1/"},{"name":"分布式共识","slug":"分布式共识","permalink":"http://example.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E5%85%B1%E8%AF%86/"},{"name":"领导选举","slug":"领导选举","permalink":"http://example.com/tags/%E9%A2%86%E5%AF%BC%E9%80%89%E4%B8%BE/"},{"name":"NoSQL","slug":"NoSQL","permalink":"http://example.com/tags/NoSQL/"},{"name":"MongoDB","slug":"MongoDB","permalink":"http://example.com/tags/MongoDB/"},{"name":"Index","slug":"Index","permalink":"http://example.com/tags/Index/"},{"name":"分布式事务","slug":"分布式事务","permalink":"http://example.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/"},{"name":"Mysql","slug":"Mysql","permalink":"http://example.com/tags/Mysql/"},{"name":"JVM","slug":"JVM","permalink":"http://example.com/tags/JVM/"},{"name":"JAVA","slug":"JAVA","permalink":"http://example.com/tags/JAVA/"},{"name":"微服务","slug":"微服务","permalink":"http://example.com/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"远程调用","slug":"远程调用","permalink":"http://example.com/tags/%E8%BF%9C%E7%A8%8B%E8%B0%83%E7%94%A8/"},{"name":"OpenApi","slug":"OpenApi","permalink":"http://example.com/tags/OpenApi/"},{"name":"微服务组件","slug":"微服务组件","permalink":"http://example.com/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E7%BB%84%E4%BB%B6/"},{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://example.com/tags/Spring-Cloud/"},{"name":"服务限流","slug":"服务限流","permalink":"http://example.com/tags/%E6%9C%8D%E5%8A%A1%E9%99%90%E6%B5%81/"},{"name":"服务熔断","slug":"服务熔断","permalink":"http://example.com/tags/%E6%9C%8D%E5%8A%A1%E7%86%94%E6%96%AD/"},{"name":"Sentinel","slug":"Sentinel","permalink":"http://example.com/tags/Sentinel/"},{"name":"注册发现","slug":"注册发现","permalink":"http://example.com/tags/%E6%B3%A8%E5%86%8C%E5%8F%91%E7%8E%B0/"},{"name":"Nacos","slug":"Nacos","permalink":"http://example.com/tags/Nacos/"},{"name":"Api Doc","slug":"Api-Doc","permalink":"http://example.com/tags/Api-Doc/"},{"name":"jwt","slug":"jwt","permalink":"http://example.com/tags/jwt/"},{"name":"MVCC","slug":"MVCC","permalink":"http://example.com/tags/MVCC/"},{"name":"日志文件","slug":"日志文件","permalink":"http://example.com/tags/%E6%97%A5%E5%BF%97%E6%96%87%E4%BB%B6/"},{"name":"Test","slug":"Test","permalink":"http://example.com/tags/Test/"},{"name":"mysql","slug":"mysql","permalink":"http://example.com/tags/mysql/"},{"name":"architecture","slug":"architecture","permalink":"http://example.com/tags/architecture/"}]}